{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "02-bandits-thompson-sampling.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlnftHF0waPf",
        "colab_type": "text"
      },
      "source": [
        "# Thompson Sampling\n",
        "\n",
        "Thompson sampling is an ingenious algorithm that implicitly balances exploration and exploitation based on quality and uncertainty. Let's say we sample a 3-armed bandit and model the probability that each arm gives us a positive reward. The goal is of course to maximize our rewards by pulling the most promising arm. Assume at the current timestep arm-3 has mean reward of 0.9 over 800 pulls, arm-2 has mean reward of 0.8 over 800 pulls, and arm-1 has mean reward of 0.78 over 10 pulls. So far, arm-3 is clearly the best. But if we were to explore, would we choose arm-2 or arm-1? An $\\epsilon$-greedy algorithm would, with probability $\\epsilon$, just as likely choose arm-3, arm-2, or arm-1. However, arm-2 has been examined many times, as many as arm-1, and has a mean reward lower than arm-1. Selecting arm-2 seems like a wasteful exploratory action. Arm-1 however, has a lower mean reward than either arm-2 or arm-3, but has only been pulled a few times. In other words, arm-1 has a higher chance of being a better action than arm-3 when compared to arm-2, since we are more uncertain about its true value. The $\\epsilon$-greedy algorithm completely misses this point. Thompson sampling, on the other hand, incorporates uncertainty by modelling the bandit's Bernouilli parameter with a prior beta distribution.\n",
        "\n",
        "The beauty of the algorithm is that it always chooses the action with the highest expected reward, with the twist that this reward is weighted by uncertainty. It is in fact a Bayesian approach to the bandit problem. In our Bernouilli bandit setup, each action $k$ returns reward of 1 with probability $\\theta_k$, and 0 with probability $1-\\theta_k$. At the beginning of a simulation, each $\\theta_k$ is sampled from a uniform distribution $\\theta_k \\sim Uniform(0,1)$ with $\\theta_k$ held constant for the rest of that simulation (in the stationary case). The agent begins with a prior belief of the reward of each arm $k$ with a beta distribution, where $\\alpha = \\beta = 1$. The prior probability density of each $\\theta_k$ is:\n",
        "\n",
        "$$\n",
        "p(\\theta_k) = \\frac{\\Gamma(\\alpha_k + \\beta_k)}{\\Gamma(\\alpha_k)\\Gamma(\\beta_k)} \\theta_k^{\\alpha_k -1} (1-\\theta_k)^{\\beta_k-1}\n",
        "$$\n",
        "An action is chosen by first sampling from the beta distribution, followed by choosing the action with highest mean reward:$$\n",
        "x_t = \\text{argmax}_k (\\hat{\\theta}_k), \\quad \\hat{\\theta}_k \\sim \\text{beta}(\\alpha_k, \\beta_k)\n",
        "$$\n",
        "\n",
        "According to Bayes' rule, an action's posterior distribution is updated depending on the reward $r_t$ received:$$\n",
        "(\\alpha_k, \\beta_k) = (\\alpha_k, \\beta_k) + (r_t, 1-r_t)\n",
        "$$\n",
        "\n",
        "Thus the actions' posterior distribution are constantly updated throughout the simulation. We will measure the Thompson algorithm by comparing it with the $\\epsilon$-greedy and Upper Confidence Bound (UCB) algorithms using regret. The per-period regret for the Bernouilli bandit problem is the difference between the mean reward of the optimal action minus the mean reward of the selected action:$$\n",
        "\\text{regret}_t(\\theta) = \\max_k \\theta_k - \\theta_{x_t}\n",
        "$$\n",
        "\n",
        "First we setup the necessary imports and the standard k-armed bandit. The get_reward_regret samples the reward for the given action, and returns the regret based on the true best action.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r5ZBjbXUwaPj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from pdb import set_trace\n",
        "\n",
        "stationary = True\n",
        "class Bandit():\n",
        "    def __init__(self, arm_count):\n",
        "        \"\"\"\n",
        "        Multi-armed bandit with rewards 1 or 0\n",
        "        At initialization, multiple arms are created. The probability of each arm returning reward 1 \n",
        "        if pulled is sample from Bernoulli(p), where randomly chosen from Uniform(0, 1) at initization\n",
        "        \"\"\"\n",
        "        self.arm_count = arm_count\n",
        "        self.generate_thetas()\n",
        "        self.timestep = 0\n",
        "        global stationary\n",
        "        self.stationary=stationary\n",
        "        \n",
        "    def generate_thetas(self):\n",
        "        self.thetas = np.random.uniform(0, 1, self.arm_count)\n",
        "        \n",
        "    def get_reward_regret(self, arm):\n",
        "        \"\"\"\n",
        "        Returns random reward for arm action. Assument action are zero-indexed\n",
        "        Args:\n",
        "            arg is an int\n",
        "        \"\"\"\n",
        "        self.timestep += 1\n",
        "        if (self.stationary==False) and (self.timestep%100 == 0) :\n",
        "          self.generate_thetas()\n",
        "        # Simulate bernouilli sampling\n",
        "        sim = np.random.uniform(0,1,self.arm_count)\n",
        "        rewards = (sim<self.thetas).astype(int)\n",
        "        reward = rewards[arm]\n",
        "        regret = self.thetas.max() - self.thetas[arm]\n",
        "\n",
        "        return reward, regret"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j86M4uFcwaPo",
        "colab_type": "text"
      },
      "source": [
        "We implement the two beta algorithms from [1], although we focus only on the Thompson algorithm. For the Bernouilli-greedy algorithm, the Bernouilli parameters are the expected values of the Beta distribution, i.e.:$$\n",
        "\\mathbb{E}(x_k) = \\frac{\\alpha_k}{(\\alpha_k + \\beta_k)}\n",
        "$$\n",
        "\n",
        "The Thompson algorithm follows the pseudocode below, based on [1]\n",
        "\n",
        "Algorithm: Thompson($K$,$\\alpha$, $\\beta$)\n",
        "<br>for $t$ = 1,2, ..., do<br>\n",
        "   &emsp;// sample action parameter from beta distribution<br>\n",
        "   &emsp;for $k = 1, \\dots, K$ do<br>\n",
        "      &emsp;&emsp;Sample $\\hat{\\theta}_k \\sim \\text{beta}(\\alpha_k, \\beta_k)$<br>\n",
        "   &emsp;end for<br>\n",
        "   \n",
        "   &emsp;// select action, get reward<br>\n",
        "   &emsp;$x_t \\leftarrow \\text{argmax}_k \\hat{\\theta}_k$<br>\n",
        "   &emsp;$r_t \\leftarrow \\text{observe}(x_t)$<br>\n",
        "\n",
        "   &emsp;// update beta parameters<br>\n",
        "   &emsp;$(\\alpha_{x_t}, \\beta_{x_t}) \\leftarrow (\\alpha_{x_t}, \\beta_{x_t})+(r_t, 1-r_t)$<br>\n",
        "end for"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6Q7GRawwaPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BetaAlgo():\n",
        "  \"\"\"\n",
        "  The algos try to learn which Bandit arm is the best to maximize reward.\n",
        "  \n",
        "  It does this by modelling the distribution of the Bandit arms with a Beta, \n",
        "  assuming the true probability of success of an arm is Bernouilli distributed.\n",
        "  \"\"\"\n",
        "  def __init__(self, bandit):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      bandit: the bandit class the algo is trying to model\n",
        "    \"\"\"\n",
        "    self.bandit = bandit\n",
        "    self.arm_count = bandit.arm_count\n",
        "    self.alpha = np.ones(self.arm_count)\n",
        "    self.beta = np.ones(self.arm_count)\n",
        "  \n",
        "  def get_reward_regret(self, arm):\n",
        "    reward, regret = self.bandit.get_reward_regret(arm)\n",
        "    self._update_params(arm, reward)\n",
        "    return reward, regret\n",
        "  \n",
        "  def _update_params(self, arm, reward):\n",
        "    self.alpha[arm] += reward\n",
        "    self.beta[arm] += 1 - reward\n",
        "\n",
        "class BernGreedy(BetaAlgo):\n",
        "  def __init__(self, bandit):\n",
        "    super().__init__(bandit)\n",
        "  \n",
        "  @staticmethod\n",
        "  def name():\n",
        "    return 'beta-greedy'\n",
        "   \n",
        "  def get_action(self):\n",
        "    \"\"\" Bernouilli parameters are the expected values of the beta\"\"\"\n",
        "    theta = self.alpha / (self.alpha + self.beta)\n",
        "    return theta.argmax()\n",
        "  \n",
        "class BernThompson(BetaAlgo):\n",
        "  def __init__(self, bandit):\n",
        "    super().__init__(bandit)\n",
        "\n",
        "  @staticmethod\n",
        "  def name():\n",
        "    return 'thompson'\n",
        "  \n",
        "  def get_action(self):\n",
        "    \"\"\" Bernouilli parameters are sampled from the beta\"\"\"\n",
        "    theta = np.random.beta(self.alpha, self.beta)\n",
        "    return theta.argmax()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1s0641Q1eRU",
        "colab_type": "text"
      },
      "source": [
        "For comparison, we also implement the $\\epsilon$-greedy algorithm and Upper Confidence Bound (UBC) algorithm. The implementations are based on [2] (pages 24-28). The $\\epsilon$-greedy algorithm is straightforward and explained briefly above. Note in this implementation we make use of the incremental update rule. That is, to update the $Q$-value of each action, we maintain a count of each action. For action $k$ taken at time $t$:$$\n",
        "\\begin{align}\n",
        "r_t &amp;\\leftarrow \\text{observe}(k) \\\\\n",
        "N(k) &amp;\\leftarrow N(k) + 1 \\\\\n",
        "Q(k) &amp;\\leftarrow Q(k) + \\frac{1}{N(k)}[r_t-Q(k)] \\\\\n",
        "\\end{align}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g61_eA1gwaPz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epsilon = 0.1\n",
        "class EpsilonGreedy():\n",
        "  \"\"\"\n",
        "  Epsilon Greedy with incremental update.\n",
        "  Based on Sutton and Barto pseudo-code, page. 24\n",
        "  \"\"\"\n",
        "  def __init__(self, bandit):\n",
        "    global epsilon\n",
        "    self.epsilon = epsilon\n",
        "    self.bandit = bandit\n",
        "    self.arm_count = bandit.arm_count\n",
        "    self.Q = np.zeros(self.arm_count) # q-value of actions\n",
        "    self.N = np.zeros(self.arm_count) # action count\n",
        "  \n",
        "  @staticmethod\n",
        "  def name():\n",
        "    return 'epsilon-greedy'\n",
        "  \n",
        "  def get_action(self):\n",
        "    if np.random.uniform(0,1) > self.epsilon:\n",
        "      action = self.Q.argmax()\n",
        "    else:\n",
        "      action = np.random.randint(0, self.arm_count)\n",
        "    return action\n",
        "  \n",
        "  def get_reward_regret(self, arm):\n",
        "    reward, regret = self.bandit.get_reward_regret(arm)\n",
        "    self._update_params(arm, reward)\n",
        "    return reward, regret\n",
        "  \n",
        "  def _update_params(self, arm, reward):\n",
        "    self.N[arm] += 1 # increment action count\n",
        "    self.Q[arm] += 1/self.N[arm] * (reward - self.Q[arm]) # inc. update rule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VpoA3XNu1v6I",
        "colab_type": "text"
      },
      "source": [
        "The UCB action selection is different to the $\\epsilon$-greedy. Like the Thompson algorithm, it includes a measure of uncertainty. The selected action follows the rule:$$\n",
        "A_t = \\text{argmax}_a \\left[ Q_t(a) + c \\sqrt{\\frac{\\ln t}{N_t (a)}} \\right]\n",
        "$$\n",
        "\n",
        "Where $N_t (a)$ is the number of times action $a$ has been selected up to time $t$. As the denominator grows in the square root expression, the added effect on $Q_t(a)$ diminishes. This uncertainty measure is weighed by the hyperparameter $c$. The disadvantage is that, unlike the Thompson algorithm, this uncertainty hyperparameter requires tuning. Fundamentally, the UCB uncertainty is deterministic and beneficial, whereas in the Thompson case, uncertainty increases the expected reward variance. Since the Thompson algorithm samples the mean rewards from a beta distribution, the actions with high variance may not only have a higher chance of being chosen, but may also have a lower chance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHnxRiS8waP3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ucb_c = 2\n",
        "class UCB():\n",
        "  \"\"\"\n",
        "  Epsilon Greedy with incremental update.\n",
        "  Based on Sutton and Barto pseudo-code, page. 24\n",
        "  \"\"\"\n",
        "  def __init__(self, bandit):\n",
        "    global ucb_c\n",
        "    self.ucb_c = ucb_c\n",
        "    self.bandit = bandit\n",
        "    self.arm_count = bandit.arm_count\n",
        "    self.Q = np.zeros(self.arm_count) # q-value of actions\n",
        "    self.N = np.zeros(self.arm_count) + 0.0001 # action count\n",
        "    self.timestep = 1\n",
        "  \n",
        "  @staticmethod\n",
        "  def name():\n",
        "    return 'ucb'\n",
        "  \n",
        "  def get_action(self):\n",
        "    ln_timestep = np.log(np.full(self.arm_count, self.timestep))\n",
        "    confidence = self.ucb_c * np.sqrt(ln_timestep/self.N)\n",
        "    action = np.argmax(self.Q + confidence)\n",
        "    self.timestep += 1\n",
        "    return action\n",
        "  \n",
        "  def get_reward_regret(self, arm):\n",
        "    reward, regret = self.bandit.get_reward_regret(arm)\n",
        "    self._update_params(arm, reward)\n",
        "    return reward, regret\n",
        "  \n",
        "  def _update_params(self, arm, reward):\n",
        "    self.N[arm] += 1 # increment action count\n",
        "    self.Q[arm] += 1/self.N[arm] * (reward - self.Q[arm]) # inc. update rule"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTCIcY9V1-tx",
        "colab_type": "text"
      },
      "source": [
        "Below are some helper functions. The function simulate will simulate the learning for a single algorithm and return the mean regrets over a number of trials. The experiment function runs the simulations over all algorithms and plots their mean regrets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SaYNgQek1-Tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_data(y):\n",
        "  \"\"\" y is a 1D vector \"\"\"\n",
        "  x = np.arange(y.size)\n",
        "  _ = plt.plot(x, y, 'o')\n",
        "  \n",
        "def multi_plot_data(data, names):\n",
        "  \"\"\" data, names are lists of vectors \"\"\"\n",
        "  x = np.arange(data[0].size)\n",
        "  for i, y in enumerate(data):\n",
        "    plt.plot(x, y, 'o', markersize=2, label=names[i])\n",
        "  plt.legend(loc='upper right', prop={'size': 16}, numpoints=10)\n",
        "  plt.show()\n",
        "  \n",
        "def simulate(simulations, timesteps, arm_count, Algorithm):\n",
        "  \"\"\" Simulates the algorithm over 'simulations' epochs \"\"\"\n",
        "  sum_regrets = np.zeros(timesteps)\n",
        "  for e in range(simulations):\n",
        "    bandit = Bandit(arm_count)\n",
        "    algo = Algorithm(bandit)\n",
        "    regrets = np.zeros(timesteps)\n",
        "    for i in range(timesteps):\n",
        "      action = algo.get_action()\n",
        "      reward, regret = algo.get_reward_regret(action)\n",
        "      regrets[i] = regret\n",
        "    sum_regrets += regrets  \n",
        "  mean_regrets = sum_regrets / simulations\n",
        "  return mean_regrets\n",
        "\n",
        "def experiment(arm_count, timesteps=1000, simulations=1000):\n",
        "  \"\"\" \n",
        "  Standard setup across all experiments \n",
        "  Args:\n",
        "    timesteps: (int) how many steps for the algo to learn the bandit\n",
        "    simulations: (int) number of epochs\n",
        "  \"\"\"\n",
        "  algos = [EpsilonGreedy, UCB, BernThompson]\n",
        "  regrets = []\n",
        "  names = []\n",
        "  for algo in algos:\n",
        "    regrets.append(simulate(simulations, timesteps, arm_count, algo))\n",
        "    names.append(algo.name())\n",
        "  multi_plot_data(regrets, names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2nbbytP2Eoc",
        "colab_type": "text"
      },
      "source": [
        "## Experiments\n",
        "For all experiments, in each trial the agents are allowed 1000 timesteps to maximize reward. We perform 5000 trials for each experiment.\n",
        "\n",
        "### Baseline\n",
        "In this first experiment, we aim for a standard setup, inspired by the bandit testbed in Chapter 2 of [2]. We set $\\epsilon=0.1$ for the $\\epsilon$-greedy algorithm, and $c=2$ for UCB. As can be seen in the chart below, the Thompson and $\\epsilon$-greedy agents quickly converge to a steady regret value after only 200 steps. The UCB agent on the other hand very slowly decreases, lagging behind the two other agents, and continues in its downward trend even at step 1000. This suggests the non-Thompson agents could benefit from parameter tuning, whereas the Thompson agent works well right off the bat."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jWipqCk9waP7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "f7c1f91f-0329-48bd-f802-95179f10d5b0"
      },
      "source": [
        "# Experiment 1\n",
        "arm_count = 10 # number of arms in bandit\n",
        "epsilon = 0.1\n",
        "ucb_c = 2\n",
        "stationary=True\n",
        "experiment(arm_count)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIAhCHPL/ANM5j4lN3Ax4AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tZzDsgH5waQA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dTGmgHJowaQE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_dCsY-pwaQI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gDBkZ5CGwaQM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8gTxwwxJwaQQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0OkqzvjwaQU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}