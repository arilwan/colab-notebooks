{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "doom-reinforce-montecarlo.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/doom_reinforce_montecarlo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTqxUWN0ffBn",
        "colab_type": "text"
      },
      "source": [
        "# Doom: REINFORCE Monte Carlo Policy Gradients üïπÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEphajumfa2E",
        "colab_type": "code",
        "outputId": "e5d88d33-ccf5-4423-ee03-a124688a51b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Nov 13 03:11:24 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.50       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   32C    P8    25W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atUAA-yFjHYG",
        "colab_type": "text"
      },
      "source": [
        "### 1. Build dependencies üèóÔ∏è"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3bWqxz8NjHDF",
        "colab_type": "code",
        "outputId": "994145c9-3b25-479c-866b-3ece76d22efe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 622
        }
      },
      "source": [
        "%%bash\n",
        "# Based on: \n",
        "# https://github.com/mwydmuch/ViZDoom/blob/master/doc/Building.md#-linux\n",
        "\n",
        "# ZDoom dependencies\n",
        "apt-get install build-essential zlib1g-dev libsdl2-dev libjpeg-dev \\\n",
        "nasm tar libbz2-dev libgtk2.0-dev cmake git libfluidsynth-dev libgme-dev \\\n",
        "libopenal-dev timidity libwildmidi-dev unzip\n",
        "\n",
        "# Boost libraries\n",
        "sudo apt-get install libboost-all-dev\n",
        "\n",
        "# Python 3 dependencies\n",
        "sudo apt-get install python3-dev python3-pip\n",
        "\n",
        "# Lua binding dependencies\n",
        "apt-get install liblua5.1-dev\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "build-essential is already the newest version (12.4ubuntu1).\n",
            "libgtk2.0-dev is already the newest version (2.24.32-1ubuntu1).\n",
            "libjpeg-dev is already the newest version (8c-2ubuntu8).\n",
            "unzip is already the newest version (6.0-21ubuntu1).\n",
            "zlib1g-dev is already the newest version (1:1.2.11.dfsg-0ubuntu2).\n",
            "libfluidsynth-dev is already the newest version (1.1.9-1).\n",
            "libgme-dev is already the newest version (0.6.2-1).\n",
            "libopenal-dev is already the newest version (1:1.18.2-2).\n",
            "libwildmidi-dev is already the newest version (0.4.2-1).\n",
            "nasm is already the newest version (2.13.02-0.1).\n",
            "timidity is already the newest version (2.13.2-41).\n",
            "cmake is already the newest version (3.10.2-1ubuntu2.18.04.1).\n",
            "git is already the newest version (1:2.17.1-1ubuntu0.4).\n",
            "libbz2-dev is already the newest version (1.0.6-8.1ubuntu0.2).\n",
            "tar is already the newest version (1.29b-2ubuntu0.1).\n",
            "libsdl2-dev is already the newest version (2.0.8+dfsg1-1ubuntu1.18.04.4).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "libboost-all-dev is already the newest version (1.65.1.0ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "python3-dev is already the newest version (3.6.7-1~18.04).\n",
            "python3-pip is already the newest version (9.0.1-2.3~ubuntu1.18.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n",
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "liblua5.1-0-dev is already the newest version (5.1.5-8.1build2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 35 not upgraded.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhdM6_Qskh56",
        "colab_type": "code",
        "outputId": "dfefa617-8100-4139-da23-aeadae296374",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!pip install vizdoom"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: vizdoom in /usr/local/lib/python3.6/dist-packages (1.1.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from vizdoom) (1.17.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cgBcayITU0em"
      },
      "source": [
        "### 2. Import libraries üìö"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSRku8dxf2AU",
        "colab_type": "code",
        "outputId": "c8b15c1e-68ce-48cb-aed3-fd398e5476af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import random\n",
        "import gym\n",
        "import time\n",
        "import warnings\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from vizdoom import *\n",
        "from skimage import transform\n",
        "from collections import deque\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.15.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3SrLCt_PgLxQ",
        "colab_type": "text"
      },
      "source": [
        "### 3. Create our environment üéÆ\n",
        "\n",
        "- Our environment takes:\n",
        "\n",
        "  - A game configuration file that handles all the options\n",
        "  - A configuration file with scenario specific options.\n",
        "\n",
        "We have 3 possible actions: turn left, turn right and shoot [[0,0,1], [1,0,0], [0,1,0]].\n",
        "\n",
        "- Agents should learn that killing monsters is GOOD and being killed is BAD.\n",
        "Additionally, wasting amunition is not ideal.\n",
        "\n",
        "- Agent is rewarded only for killing monsters so he has to figure out the rest for himself.\n",
        "\n",
        "- Map is a large circle. Player is spawned in the exact center. Monsters are spawned along the wall.\n",
        "\n",
        "- Monsters are killed after a single shot.\n",
        "\n",
        "- After dying each monster is respawned after some time.\n",
        "\n",
        "- Episodes end when the player dies (it's inevitable becuse of limitted ammo).\n",
        "\n",
        "REWARDS:\n",
        "+1 for killing a monster\n",
        "\n",
        "3 available buttons: turn left, turn right, shoot (attack)\n",
        "death penalty = 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-IXQj2hgLWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\"\"\"\n",
        "\"\"\"\n",
        "def create_environment():\n",
        "  game = DoomGame()\n",
        "\n",
        "  # load the corrent configuration\n",
        "  game.load_config('defend_the_center.cfg')\n",
        "\n",
        "  # load the correct scenario (in our case defend_center scenario)\n",
        "  game.set_doom_scenario_path('defend_the_center.wad')\n",
        "\n",
        "  game.set_window_visible(False)\n",
        "\n",
        "  game.init()\n",
        "\n",
        "  # Here our possible actions\n",
        "  # [[1,0,0],[0,1,0],[0,0,1]]\n",
        "  possible_actions  = np.identity(3,dtype=int).tolist()\n",
        "\n",
        "  return game, possible_actions\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-LCzSHdBN43",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "game, possible_actions = create_environment()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XfApD94F6xJr",
        "colab_type": "text"
      },
      "source": [
        "### 4. Utility functions\n",
        "\n",
        "preprocess_frame()\n",
        "\n",
        "Preprocessing is an important step, because we want to reduce the complexity of our states to reduce the computation time needed for training.\n",
        "\n",
        "Our steps:\n",
        "\n",
        "- Grayscale each of our frames (because color does not add important information). But this is already done by the config file.\n",
        "- Crop the screen by removing the score bar.\n",
        "- Normalize pixel values.\n",
        "- Resize the preprocessed frame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "stP13cSO6xB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess_frame(frame):\n",
        "  # Crop the frame to remove the score and status bar.\n",
        "  cropped_frame = frame[40:,:]\n",
        "\n",
        "  # normalize pixel values\n",
        "  normalized_frame = cropped_frame/255.0\n",
        "\n",
        "  # resize\n",
        "  reduced_frame = transform.resize(normalized_frame, [100, 160])\n",
        "\n",
        "  return reduced_frame\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huaxizBt6w38",
        "colab_type": "text"
      },
      "source": [
        "stack_frames()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBjCPzhk6wuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stack_size = 4\n",
        "stacked_frames = deque([np.zeros((100,160), dtype=np.int) for i in range(stack_size)], maxlen=4)\n",
        "\n",
        "def stack_frames(stacked_frames, state, is_new_episode):\n",
        "  # preprocess frame\n",
        "  frame = preprocess_frame(state)\n",
        "\n",
        "  if is_new_episode:\n",
        "    stacked_frames = deque([np.zeros((100, 160), dtype=np.int) for i in range(stack_size)],\n",
        "                           maxlen=4)\n",
        "    stacked_frames.append(frame)\n",
        "    stacked_frames.append(frame)\n",
        "    stacked_frames.append(frame)\n",
        "    stacked_frames.append(frame)\n",
        "    \n",
        "    stacked_state = np.stack(stacked_frames, axis=2)\n",
        "\n",
        "  else: \n",
        "    stacked_frames.append(frame)\n",
        "    stacked_state = np.stack(stacked_frames, axis=2)\n",
        "\n",
        "  return stacked_state, stacked_frames\n",
        "\n",
        "\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkADBW7w6wf4",
        "colab_type": "text"
      },
      "source": [
        "**discount_and_normalize_rewards()**üí∞\n",
        "\n",
        "We need to discount rewards at the end of the episode."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dtycXBtq6wNh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def discount_and_normalize_rewards(episode_rewards):\n",
        "  discounted_episode_rewards = np.zeros_like(episode_rewards)\n",
        "  cumulative = 0.0\n",
        "  for i in reversed(range(len(episode_rewards))):\n",
        "    cumulative = cumulative * gamma + episode_rewards[i]\n",
        "    discounted_episode_rewards[i] = cumulative\n",
        "\n",
        "  mean = np.mean(discounted_episode_rewards)\n",
        "  std = np.std(discounted_episode_rewards)\n",
        "  discounted_episode_rewards = (discounted_episode_rewards - mean) / std\n",
        "  return discounted_episode_rewards\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FH1Nuurdg1DY",
        "colab_type": "text"
      },
      "source": [
        "### 5. Define hyperparameters ‚öóÔ∏è\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8SER31Rg0oP",
        "colab_type": "code",
        "outputId": "bee91291-130b-4a82-c7ba-7538fc50d261",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# environment hyperparameters\n",
        "state_size = [100, 160, 4]\n",
        "action_size = game.get_available_buttons_size()\n",
        "stack_size = 4\n",
        "\n",
        "# training hyperparameters\n",
        "learning_rate = 0.0001\n",
        "num_epochs = 1000\n",
        "batch_size = 1000\n",
        "gamma = 0.99\n",
        "\n",
        "training = True\n",
        "\n",
        "print('Action size:', action_size)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Action size: 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Loq5qBDzhf0r",
        "colab_type": "text"
      },
      "source": [
        "### 5. Create our Policy Gradient NN model üß†"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9EC9lSiys9_",
        "colab_type": "text"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u1M0BS9LhVxE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PGNetwork:\n",
        "    def __init__(self, state_size, action_size, learning_rate, name='PGNetwork'):\n",
        "        self.state_size = state_size\n",
        "        self.action_size = action_size\n",
        "        self.learning_rate = learning_rate\n",
        "        \n",
        "        with tf.variable_scope(name):\n",
        "            with tf.name_scope(\"inputs\"):\n",
        "                # We create the placeholders\n",
        "                # *state_size means that we take each elements of state_size in tuple hence is like if we wrote\n",
        "                # [None, 84, 84, 4]\n",
        "                self.inputs_= tf.placeholder(tf.float32, [None, *state_size], name=\"inputs_\")\n",
        "                self.actions = tf.placeholder(tf.int32, [None, action_size], name=\"actions\")\n",
        "                self.discounted_episode_rewards_ = tf.placeholder(tf.float32, [None, ], name=\"discounted_episode_rewards_\")\n",
        "            \n",
        "                \n",
        "                # Add this placeholder for having this variable in tensorboard\n",
        "                self.mean_reward_ = tf.placeholder(tf.float32, name=\"mean_reward\")\n",
        "                \n",
        "            with tf.name_scope(\"conv1\"):\n",
        "                \"\"\"\n",
        "                First convnet:\n",
        "                CNN\n",
        "                BatchNormalization\n",
        "                ELU\n",
        "                \"\"\"\n",
        "                # Input is 84x84x4\n",
        "                self.conv1 = tf.layers.conv2d(inputs = self.inputs_,\n",
        "                                             filters = 32,\n",
        "                                             kernel_size = [8,8],\n",
        "                                             strides = [4,4],\n",
        "                                             padding = \"VALID\",\n",
        "                                              kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "                                             name = \"conv1\")\n",
        "\n",
        "                self.conv1_batchnorm = tf.layers.batch_normalization(self.conv1,\n",
        "                                                       training = True,\n",
        "                                                       epsilon = 1e-5,\n",
        "                                                         name = 'batch_norm1')\n",
        "\n",
        "                self.conv1_out = tf.nn.elu(self.conv1_batchnorm, name=\"conv1_out\")\n",
        "                ## --> [20, 20, 32]\n",
        "            \n",
        "            with tf.name_scope(\"conv2\"):\n",
        "                \"\"\"\n",
        "                Second convnet:\n",
        "                CNN\n",
        "                BatchNormalization\n",
        "                ELU\n",
        "                \"\"\"\n",
        "                self.conv2 = tf.layers.conv2d(inputs = self.conv1_out,\n",
        "                                     filters = 64,\n",
        "                                     kernel_size = [4,4],\n",
        "                                     strides = [2,2],\n",
        "                                     padding = \"VALID\",\n",
        "                                    kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "                                     name = \"conv2\")\n",
        "\n",
        "                self.conv2_batchnorm = tf.layers.batch_normalization(self.conv2,\n",
        "                                                       training = True,\n",
        "                                                       epsilon = 1e-5,\n",
        "                                                         name = 'batch_norm2')\n",
        "\n",
        "                self.conv2_out = tf.nn.elu(self.conv2_batchnorm, name=\"conv2_out\")\n",
        "                ## --> [9, 9, 64]\n",
        "            \n",
        "            with tf.name_scope(\"conv3\"):\n",
        "                \"\"\"\n",
        "                Third convnet:\n",
        "                CNN\n",
        "                BatchNormalization\n",
        "                ELU\n",
        "                \"\"\"\n",
        "                self.conv3 = tf.layers.conv2d(inputs = self.conv2_out,\n",
        "                                     filters = 128,\n",
        "                                     kernel_size = [4,4],\n",
        "                                     strides = [2,2],\n",
        "                                     padding = \"VALID\",\n",
        "                                    kernel_initializer=tf.contrib.layers.xavier_initializer_conv2d(),\n",
        "                                     name = \"conv3\")\n",
        "\n",
        "                self.conv3_batchnorm = tf.layers.batch_normalization(self.conv3,\n",
        "                                                       training = True,\n",
        "                                                       epsilon = 1e-5,\n",
        "                                                         name = 'batch_norm3')\n",
        "\n",
        "                self.conv3_out = tf.nn.elu(self.conv3_batchnorm, name=\"conv3_out\")\n",
        "                ## --> [3, 3, 128]\n",
        "            \n",
        "            with tf.name_scope(\"flatten\"):\n",
        "                self.flatten = tf.layers.flatten(self.conv3_out)\n",
        "                ## --> [1152]\n",
        "            \n",
        "            with tf.name_scope(\"fc1\"):\n",
        "                self.fc = tf.layers.dense(inputs = self.flatten,\n",
        "                                      units = 512,\n",
        "                                      activation = tf.nn.elu,\n",
        "                                           kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "                                    name=\"fc1\")\n",
        "            \n",
        "            with tf.name_scope(\"logits\"):\n",
        "                self.logits = tf.layers.dense(inputs = self.fc, \n",
        "                                               kernel_initializer=tf.contrib.layers.xavier_initializer(),\n",
        "                                              units = 3, \n",
        "                                            activation=None)\n",
        "            \n",
        "            with tf.name_scope(\"softmax\"):\n",
        "                self.action_distribution = tf.nn.softmax(self.logits)\n",
        "                \n",
        "\n",
        "            with tf.name_scope(\"loss\"):\n",
        "                # tf.nn.softmax_cross_entropy_with_logits computes the cross entropy of the result after applying the softmax function\n",
        "                # If you have single-class labels, where an object can only belong to one class, you might now consider using \n",
        "                # tf.nn.sparse_softmax_cross_entropy_with_logits so that you don't have to convert your labels to a dense one-hot array. \n",
        "                self.neg_log_prob = tf.nn.softmax_cross_entropy_with_logits_v2(logits = self.logits, labels = self.actions)\n",
        "                self.loss = tf.reduce_mean(self.neg_log_prob * self.discounted_episode_rewards_) \n",
        "        \n",
        "    \n",
        "            with tf.name_scope(\"train\"):\n",
        "                self.train_opt = tf.train.RMSPropOptimizer(self.learning_rate).minimize(self.loss)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cD4Qryga0te9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Reset the graph\n",
        "tf.reset_default_graph()\n",
        "\n",
        "# Instantiate the PGNetwork\n",
        "PGNetwork = PGNetwork(state_size, action_size, learning_rate)\n",
        "\n",
        "# Initialize Session\n",
        "sess = tf.Session()\n",
        "init = tf.global_variables_initializer()\n",
        "sess.run(init)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-tgOXs1VS3F",
        "colab_type": "text"
      },
      "source": [
        "### 6. Setup Tensorboard üìä"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnCbd-BXVSVv",
        "colab_type": "code",
        "outputId": "329f1931-1ce3-4af8-e918-a0386c8c38f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The tensorboard extension is already loaded. To reload it, use:\n",
            "  %reload_ext tensorboard\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALy8MsVPVSRS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Setup tensorboard writer\n",
        "writer = tf.summary.FileWriter('/tensorboard/pg/1')\n",
        "\n",
        "# loses\n",
        "tf.summary.scalar('loss', PGNetwork.loss)\n",
        "\n",
        "# reward mean\n",
        "tf.summary.scalar('reward_mean', PGNetwork.mean_reward_)\n",
        "\n",
        "write_op = tf.summary.merge_all()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uLSXb3qWUNm",
        "colab_type": "text"
      },
      "source": [
        "### 7. Train our Agent üèÉ‚Äç‚ôÇÔ∏è "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iobM-xLN2lfk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def make_batch(batch_size, stacked_frames):\n",
        "    # Initialize lists: states, actions, rewards_of_episode, rewards_of_batch, discounted_rewards\n",
        "    states, actions, rewards_of_episode, rewards_of_batch, discounted_rewards = [], [], [], [], []\n",
        "    \n",
        "    # Reward of batch is also a trick to keep track of how many timestep we made.\n",
        "    # We use to to verify at the end of each episode if > batch_size or not.\n",
        "    \n",
        "    # Keep track of how many episodes in our batch (useful when we'll need to calculate the average reward per episode)\n",
        "    episode_num  = 1\n",
        "    \n",
        "    # Launch a new episode\n",
        "    game.new_episode()\n",
        "        \n",
        "    # Get a new state\n",
        "    state = game.get_state().screen_buffer\n",
        "    state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
        "\n",
        "    while True:\n",
        "        # Run State Through Policy & Calculate Action\n",
        "        action_probability_distribution = sess.run(PGNetwork.action_distribution, \n",
        "                                                   feed_dict={PGNetwork.inputs_: state.reshape(1, *state_size)})\n",
        "        \n",
        "        # REMEMBER THAT WE ARE IN A STOCHASTIC POLICY SO WE DON'T ALWAYS TAKE THE ACTION WITH THE HIGHEST PROBABILITY\n",
        "        # (For instance if the action with the best probability for state S is a1 with 70% chances, there is\n",
        "        #30% chance that we take action a2)\n",
        "        action = np.random.choice(range(action_probability_distribution.shape[1]), \n",
        "                                  p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
        "        action = possible_actions[action]\n",
        "\n",
        "        # Perform action\n",
        "        reward = game.make_action(action)\n",
        "        done = game.is_episode_finished()\n",
        "\n",
        "        # Store results\n",
        "        states.append(state)\n",
        "        actions.append(action)\n",
        "        rewards_of_episode.append(reward)\n",
        "        \n",
        "        if done:\n",
        "            # The episode ends so no next state\n",
        "            next_state = np.zeros((100, 160), dtype=np.int)\n",
        "            next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
        "            \n",
        "            # Append the rewards_of_batch to reward_of_episode\n",
        "            rewards_of_batch.append(rewards_of_episode)\n",
        "            \n",
        "            # Calculate gamma Gt\n",
        "            discounted_rewards.append(discount_and_normalize_rewards(rewards_of_episode))\n",
        "           \n",
        "            # If the number of rewards_of_batch > batch_size stop the minibatch creation\n",
        "            # (Because we have sufficient number of episode mb)\n",
        "            # Remember that we put this condition here, because we want entire episode (Monte Carlo)\n",
        "            # so we can't check that condition for each step but only if an episode is finished\n",
        "            if len(np.concatenate(rewards_of_batch)) > batch_size:\n",
        "                break\n",
        "                \n",
        "            # Reset the transition stores\n",
        "            rewards_of_episode = []\n",
        "            \n",
        "            # Add episode\n",
        "            episode_num += 1\n",
        "            \n",
        "            # Start a new episode\n",
        "            game.new_episode()\n",
        "\n",
        "            # First we need a state\n",
        "            state = game.get_state().screen_buffer\n",
        "\n",
        "            # Stack the frames\n",
        "            state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
        "         \n",
        "        else:\n",
        "            # If not done, the next_state become the current state\n",
        "            next_state = game.get_state().screen_buffer\n",
        "            next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
        "            state = next_state\n",
        "                         \n",
        "    return np.stack(np.array(states)), np.stack(np.array(actions)), np.concatenate(rewards_of_batch), np.concatenate(discounted_rewards), episode_num"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dZz3TAdr2v97",
        "colab_type": "code",
        "outputId": "e2ad54ea-ce4a-4466-b715-c9741e5169c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Keep track of all rewards total for each batch\n",
        "allRewards = []\n",
        "\n",
        "total_rewards = 0\n",
        "maximumRewardRecorded = 0\n",
        "mean_reward_total = []\n",
        "epoch = 1\n",
        "average_reward = []\n",
        "\n",
        "# Saver\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if training:\n",
        "    # Load the model\n",
        "    #saver.restore(sess, \"./models/model.ckpt\")\n",
        "\n",
        "    while epoch < num_epochs + 1:\n",
        "        # Gather training data\n",
        "        states_mb, actions_mb, rewards_of_batch, discounted_rewards_mb, nb_episodes_mb = make_batch(batch_size, stacked_frames)\n",
        "\n",
        "        ### These part is used for analytics\n",
        "        # Calculate the total reward ot the batch\n",
        "        total_reward_of_that_batch = np.sum(rewards_of_batch)\n",
        "        allRewards.append(total_reward_of_that_batch)\n",
        "\n",
        "        # Calculate the mean reward of the batch\n",
        "        # Total rewards of batch / nb episodes in that batch\n",
        "        mean_reward_of_that_batch = np.divide(total_reward_of_that_batch, nb_episodes_mb)\n",
        "        mean_reward_total.append(mean_reward_of_that_batch)\n",
        "\n",
        "        # Calculate the average reward of all training\n",
        "        # mean_reward_of_that_batch / epoch\n",
        "        average_reward_of_all_training = np.divide(np.sum(mean_reward_total), epoch)\n",
        "\n",
        "        # Calculate maximum reward recorded \n",
        "        maximumRewardRecorded = np.amax(allRewards)\n",
        "\n",
        "        print(\"==========================================\")\n",
        "        print(\"Epoch: \", epoch, \"/\", num_epochs)\n",
        "        print(\"-----------\")\n",
        "        print(\"Number of training episodes: {}\".format(nb_episodes_mb))\n",
        "        print(\"Total reward: {}\".format(total_reward_of_that_batch, nb_episodes_mb))\n",
        "        print(\"Mean Reward of that batch {}\".format(mean_reward_of_that_batch))\n",
        "        print(\"Average Reward of all training: {}\".format(average_reward_of_all_training))\n",
        "        print(\"Max reward for a batch so far: {}\".format(maximumRewardRecorded))\n",
        "\n",
        "        # Feedforward, gradient and backpropagation\n",
        "        loss_, _ = sess.run([PGNetwork.loss, PGNetwork.train_opt], feed_dict={PGNetwork.inputs_: states_mb.reshape((len(states_mb), 100,160,4)),\n",
        "                                                            PGNetwork.actions: actions_mb,\n",
        "                                                                     PGNetwork.discounted_episode_rewards_: discounted_rewards_mb \n",
        "                                                                    })\n",
        "\n",
        "        print(\"Training Loss: {}\".format(loss_))\n",
        "\n",
        "        # Write TF Summaries\n",
        "        summary = sess.run(write_op, feed_dict={PGNetwork.inputs_: states_mb.reshape((len(states_mb), 100,160,4)),\n",
        "                                                            PGNetwork.actions: actions_mb,\n",
        "                                                                     PGNetwork.discounted_episode_rewards_: discounted_rewards_mb,\n",
        "                                                                    PGNetwork.mean_reward_: mean_reward_of_that_batch\n",
        "                                                                    })\n",
        "\n",
        "        #summary = sess.run(write_op, feed_dict={x: s_.reshape(len(s_),84,84,1), y:a_, d_r: d_r_, r: r_, n: n_})\n",
        "        writer.add_summary(summary, epoch)\n",
        "        writer.flush()\n",
        "\n",
        "        # Save Model\n",
        "        if epoch % 10 == 0:\n",
        "            saver.save(sess, \"./models/model.ckpt\")\n",
        "            print(\"Model saved\")\n",
        "        epoch += 1"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "==========================================\n",
            "Epoch:  1 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 1.0\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: 0.009648592211306095\n",
            "==========================================\n",
            "Epoch:  2 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 1.0\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.005959826521575451\n",
            "==========================================\n",
            "Epoch:  3 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 0.0\n",
            "Mean Reward of that batch 0.0\n",
            "Average Reward of all training: 0.6666666666666666\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.018194513395428658\n",
            "==========================================\n",
            "Epoch:  4 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: -2.0\n",
            "Mean Reward of that batch -0.5\n",
            "Average Reward of all training: 0.375\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: 0.009513749741017818\n",
            "==========================================\n",
            "Epoch:  5 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 0.4333333333333333\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.009177474305033684\n",
            "==========================================\n",
            "Epoch:  6 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.5\n",
            "Average Reward of all training: 0.4444444444444444\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: 0.018744776025414467\n",
            "==========================================\n",
            "Epoch:  7 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.25\n",
            "Average Reward of all training: 0.41666666666666663\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: 0.005953148473054171\n",
            "==========================================\n",
            "Epoch:  8 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: -1.0\n",
            "Mean Reward of that batch -0.25\n",
            "Average Reward of all training: 0.3333333333333333\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.008115056902170181\n",
            "==========================================\n",
            "Epoch:  9 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 0.75\n",
            "Average Reward of all training: 0.3796296296296296\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: 0.007922853343188763\n",
            "==========================================\n",
            "Epoch:  10 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.3333333333333333\n",
            "Average Reward of all training: 0.375\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.0027847997844219208\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  11 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.25\n",
            "Average Reward of all training: 0.36363636363636365\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.01062126737087965\n",
            "==========================================\n",
            "Epoch:  12 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 0.4166666666666667\n",
            "Max reward for a batch so far: 3.0\n",
            "Training Loss: -0.0036891773343086243\n",
            "==========================================\n",
            "Epoch:  13 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 0.5128205128205129\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.017641935497522354\n",
            "==========================================\n",
            "Epoch:  14 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.25\n",
            "Average Reward of all training: 0.49404761904761907\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.0057974206283688545\n",
            "==========================================\n",
            "Epoch:  15 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: -1.0\n",
            "Mean Reward of that batch -0.25\n",
            "Average Reward of all training: 0.4444444444444445\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.01995745301246643\n",
            "==========================================\n",
            "Epoch:  16 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 0.4583333333333333\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.008942936547100544\n",
            "==========================================\n",
            "Epoch:  17 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 0.0\n",
            "Mean Reward of that batch 0.0\n",
            "Average Reward of all training: 0.4313725490196078\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.0018849128391593695\n",
            "==========================================\n",
            "Epoch:  18 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 0.4444444444444444\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.01534523069858551\n",
            "==========================================\n",
            "Epoch:  19 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 0.47368421052631576\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.010038938373327255\n",
            "==========================================\n",
            "Epoch:  20 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 0.75\n",
            "Average Reward of all training: 0.4875\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.005500584840774536\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  21 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 0.75\n",
            "Average Reward of all training: 0.5\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.021778654307127\n",
            "==========================================\n",
            "Epoch:  22 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 0.537878787878788\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.009668438695371151\n",
            "==========================================\n",
            "Epoch:  23 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 0.5434782608695652\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.013862459920346737\n",
            "==========================================\n",
            "Epoch:  24 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.3333333333333333\n",
            "Average Reward of all training: 0.5347222222222222\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.023978376761078835\n",
            "==========================================\n",
            "Epoch:  25 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 0.5666666666666667\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.005563491955399513\n",
            "==========================================\n",
            "Epoch:  26 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.5\n",
            "Average Reward of all training: 0.5641025641025641\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.005344734527170658\n",
            "==========================================\n",
            "Epoch:  27 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 0.6049382716049382\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.010196652263402939\n",
            "==========================================\n",
            "Epoch:  28 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 0.619047619047619\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.0011651022359728813\n",
            "==========================================\n",
            "Epoch:  29 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.5\n",
            "Average Reward of all training: 0.6149425287356322\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: -0.007385872304439545\n",
            "==========================================\n",
            "Epoch:  30 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.25\n",
            "Average Reward of all training: 0.6027777777777777\n",
            "Max reward for a batch so far: 5.0\n",
            "Training Loss: 0.008285691030323505\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  31 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 0.6693548387096774\n",
            "Max reward for a batch so far: 8.0\n",
            "Training Loss: -0.001723835594020784\n",
            "==========================================\n",
            "Epoch:  32 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 0.7213541666666666\n",
            "Max reward for a batch so far: 8.0\n",
            "Training Loss: 0.005171600263565779\n",
            "==========================================\n",
            "Epoch:  33 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 0.75\n",
            "Max reward for a batch so far: 8.0\n",
            "Training Loss: -0.013774742372334003\n",
            "==========================================\n",
            "Epoch:  34 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 0.7573529411764706\n",
            "Max reward for a batch so far: 8.0\n",
            "Training Loss: -0.020508358255028725\n",
            "==========================================\n",
            "Epoch:  35 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 0.8023809523809523\n",
            "Max reward for a batch so far: 8.0\n",
            "Training Loss: -0.0009500945452600718\n",
            "==========================================\n",
            "Epoch:  36 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 0.8078703703703703\n",
            "Max reward for a batch so far: 8.0\n",
            "Training Loss: 0.00018107111100107431\n",
            "==========================================\n",
            "Epoch:  37 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 0.867117117117117\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.04404599964618683\n",
            "==========================================\n",
            "Epoch:  38 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 0.8881578947368419\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: 0.0243862085044384\n",
            "==========================================\n",
            "Epoch:  39 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 0.9166666666666665\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.02728707157075405\n",
            "==========================================\n",
            "Epoch:  40 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 0.9604166666666666\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: 0.01809190772473812\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  41 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 1.0101626016260161\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.014738704077899456\n",
            "==========================================\n",
            "Epoch:  42 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 1.0178571428571428\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: 0.009654397144913673\n",
            "==========================================\n",
            "Epoch:  43 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 1.0329457364341084\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: 0.010643381625413895\n",
            "==========================================\n",
            "Epoch:  44 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 1.0776515151515151\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.03395682945847511\n",
            "==========================================\n",
            "Epoch:  45 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 1.1055555555555556\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.015276649966835976\n",
            "==========================================\n",
            "Epoch:  46 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 1.1177536231884058\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: 0.01087583415210247\n",
            "==========================================\n",
            "Epoch:  47 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 1.1436170212765957\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.02363547496497631\n",
            "==========================================\n",
            "Epoch:  48 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 1.1822916666666667\n",
            "Max reward for a batch so far: 9.0\n",
            "Training Loss: -0.019443560391664505\n",
            "==========================================\n",
            "Epoch:  49 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 1.2329931972789114\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.00758477533236146\n",
            "==========================================\n",
            "Epoch:  50 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 1.2683333333333333\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.02991292253136635\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  51 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 1.2826797385620914\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.05221428722143173\n",
            "==========================================\n",
            "Epoch:  52 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 1.2964743589743588\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: 0.009734643623232841\n",
            "==========================================\n",
            "Epoch:  53 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 1.3160377358490563\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: 0.011820532381534576\n",
            "==========================================\n",
            "Epoch:  54 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 1.3533950617283947\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.01960989087820053\n",
            "==========================================\n",
            "Epoch:  55 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 1.389393939393939\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.0062510427087545395\n",
            "==========================================\n",
            "Epoch:  56 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 1.4538690476190477\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.10061278939247131\n",
            "==========================================\n",
            "Epoch:  57 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 1.5\n",
            "Average Reward of all training: 1.4546783625730995\n",
            "Max reward for a batch so far: 11.0\n",
            "Training Loss: -0.015731390565633774\n",
            "==========================================\n",
            "Epoch:  58 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 1.4985632183908046\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.03853297233581543\n",
            "==========================================\n",
            "Epoch:  59 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 1.574858757062147\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.04122566431760788\n",
            "==========================================\n",
            "Epoch:  60 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 1.6152777777777778\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.06610912084579468\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  61 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 1.6270491803278688\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.012145896442234516\n",
            "==========================================\n",
            "Epoch:  62 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 1.6330645161290323\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.027485623955726624\n",
            "==========================================\n",
            "Epoch:  63 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 3.5\n",
            "Average Reward of all training: 1.6626984126984128\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: 0.005332213826477528\n",
            "==========================================\n",
            "Epoch:  64 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 1.70703125\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.01541901659220457\n",
            "==========================================\n",
            "Epoch:  65 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 3.5\n",
            "Average Reward of all training: 1.7346153846153847\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.07410226762294769\n",
            "==========================================\n",
            "Epoch:  66 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 1.753787878787879\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.043710991740226746\n",
            "==========================================\n",
            "Epoch:  67 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 1.7773631840796018\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.03174354135990143\n",
            "==========================================\n",
            "Epoch:  68 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 1.7904411764705883\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.020758332684636116\n",
            "==========================================\n",
            "Epoch:  69 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 1.7983091787439613\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.01170098315924406\n",
            "==========================================\n",
            "Epoch:  70 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 1.8154761904761905\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.019776184111833572\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  71 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 1.8180751173708918\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.02619478851556778\n",
            "==========================================\n",
            "Epoch:  72 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 1.8206018518518516\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.007847219705581665\n",
            "==========================================\n",
            "Epoch:  73 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 1.8504566210045659\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: 0.0037488415837287903\n",
            "==========================================\n",
            "Epoch:  74 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 1.8997747747747744\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.07675596326589584\n",
            "==========================================\n",
            "Epoch:  75 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 1.9188888888888889\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.003913923166692257\n",
            "==========================================\n",
            "Epoch:  76 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 1.9528508771929822\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.08104691654443741\n",
            "==========================================\n",
            "Epoch:  77 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 1.962121212121212\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.05021590366959572\n",
            "==========================================\n",
            "Epoch:  78 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 1.9797008547008546\n",
            "Max reward for a batch so far: 12.0\n",
            "Training Loss: -0.018645722419023514\n",
            "==========================================\n",
            "Epoch:  79 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.0179324894514767\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.02485591359436512\n",
            "==========================================\n",
            "Epoch:  80 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.0385416666666667\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.022989990189671516\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  81 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.075102880658436\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.005923854187130928\n",
            "==========================================\n",
            "Epoch:  82 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.1168699186991873\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.006318475119769573\n",
            "==========================================\n",
            "Epoch:  83 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.139558232931727\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.04701954498887062\n",
            "==========================================\n",
            "Epoch:  84 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.1458333333333335\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.030874675139784813\n",
            "==========================================\n",
            "Epoch:  85 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.1480392156862744\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.024996401742100716\n",
            "==========================================\n",
            "Epoch:  86 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 2.1385658914728682\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.010201619938015938\n",
            "==========================================\n",
            "Epoch:  87 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.1369731800766285\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.011503954418003559\n",
            "==========================================\n",
            "Epoch:  88 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.1638257575757573\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.05674244463443756\n",
            "==========================================\n",
            "Epoch:  89 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.1582397003745317\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.010218839161098003\n",
            "==========================================\n",
            "Epoch:  90 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.1712962962962963\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.06596508622169495\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  91 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.191391941391941\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.06535888463258743\n",
            "==========================================\n",
            "Epoch:  92 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.203804347826087\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.028187422081828117\n",
            "==========================================\n",
            "Epoch:  93 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.239247311827957\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.021596593782305717\n",
            "==========================================\n",
            "Epoch:  94 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.2402482269503547\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.01911746710538864\n",
            "==========================================\n",
            "Epoch:  95 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.2517543859649125\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.024330956861376762\n",
            "==========================================\n",
            "Epoch:  96 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.2699652777777777\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.009841201826930046\n",
            "==========================================\n",
            "Epoch:  97 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.2843642611683848\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.010127083398401737\n",
            "==========================================\n",
            "Epoch:  98 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.3018707482993195\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.039999619126319885\n",
            "==========================================\n",
            "Epoch:  99 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.308922558922559\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.02793375961482525\n",
            "==========================================\n",
            "Epoch:  100 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.315833333333333\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.03804878517985344\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  101 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.3325082508250823\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.0116810854524374\n",
            "==========================================\n",
            "Epoch:  102 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.3423202614379086\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.024092724546790123\n",
            "==========================================\n",
            "Epoch:  103 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.3584142394822005\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.08486580103635788\n",
            "==========================================\n",
            "Epoch:  104 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.3709935897435894\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.008277708664536476\n",
            "==========================================\n",
            "Epoch:  105 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.3865079365079365\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.02951439842581749\n",
            "==========================================\n",
            "Epoch:  106 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.406446540880503\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.037551674991846085\n",
            "==========================================\n",
            "Epoch:  107 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4026479750778815\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.012851945124566555\n",
            "==========================================\n",
            "Epoch:  108 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.4220679012345676\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.03325190395116806\n",
            "==========================================\n",
            "Epoch:  109 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.4457186544342506\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.030684098601341248\n",
            "==========================================\n",
            "Epoch:  110 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4416666666666664\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.004049955401569605\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  111 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.4496996996996994\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: 0.018236635252833366\n",
            "==========================================\n",
            "Epoch:  112 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.4575892857142856\n",
            "Max reward for a batch so far: 15.0\n",
            "Training Loss: -0.04919618368148804\n",
            "==========================================\n",
            "Epoch:  113 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 2.4830383480825957\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.019599540159106255\n",
            "==========================================\n",
            "Epoch:  114 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.4846491228070176\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0037324840668588877\n",
            "==========================================\n",
            "Epoch:  115 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4804347826086954\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0035721412859857082\n",
            "==========================================\n",
            "Epoch:  116 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.49066091954023\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.04695691540837288\n",
            "==========================================\n",
            "Epoch:  117 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.4921652421652425\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.08887814730405807\n",
            "==========================================\n",
            "Epoch:  118 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.4992937853107344\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.03780393302440643\n",
            "==========================================\n",
            "Epoch:  119 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.509103641456583\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.0013424783246591687\n",
            "==========================================\n",
            "Epoch:  120 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.5076388888888888\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.12092896550893784\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  121 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.503443526170799\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.021261123940348625\n",
            "==========================================\n",
            "Epoch:  122 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.5020491803278686\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0515042245388031\n",
            "==========================================\n",
            "Epoch:  123 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4979674796747964\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.012282638810575008\n",
            "==========================================\n",
            "Epoch:  124 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.496639784946236\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.034339867532253265\n",
            "==========================================\n",
            "Epoch:  125 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.5033333333333325\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0016737213591113687\n",
            "==========================================\n",
            "Epoch:  126 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.5152116402116396\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.011403098702430725\n",
            "==========================================\n",
            "Epoch:  127 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.5190288713910753\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.014585386030375957\n",
            "==========================================\n",
            "Epoch:  128 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.5384114583333335\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.12564826011657715\n",
            "==========================================\n",
            "Epoch:  129 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.5316537467700257\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.051358792930841446\n",
            "==========================================\n",
            "Epoch:  130 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 2.5224358974358974\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.04316198080778122\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  131 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.518447837150127\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.029317887499928474\n",
            "==========================================\n",
            "Epoch:  132 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.5170454545454546\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.01213944423943758\n",
            "==========================================\n",
            "Epoch:  133 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.5106516290726812\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.0004083941166754812\n",
            "==========================================\n",
            "Epoch:  134 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 2.499378109452736\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.002976416377350688\n",
            "==========================================\n",
            "Epoch:  135 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.49320987654321\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.0022799416910856962\n",
            "==========================================\n",
            "Epoch:  136 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.4993872549019605\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.010653413832187653\n",
            "==========================================\n",
            "Epoch:  137 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4957420924574207\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.01535515021532774\n",
            "==========================================\n",
            "Epoch:  138 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.5042270531400965\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0009508234797976911\n",
            "==========================================\n",
            "Epoch:  139 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.502997601918465\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.008535558357834816\n",
            "==========================================\n",
            "Epoch:  140 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.5017857142857145\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.0033299499191343784\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  141 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.49822695035461\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.019044166430830956\n",
            "==========================================\n",
            "Epoch:  142 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.5088028169014085\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.011480383574962616\n",
            "==========================================\n",
            "Epoch:  143 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 2.5005827505827507\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.044733572751283646\n",
            "==========================================\n",
            "Epoch:  144 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.499421296296296\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.05087290704250336\n",
            "==========================================\n",
            "Epoch:  145 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.49367816091954\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.011726231314241886\n",
            "==========================================\n",
            "Epoch:  146 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.488013698630137\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.025795064866542816\n",
            "==========================================\n",
            "Epoch:  147 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.482426303854875\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.017791159451007843\n",
            "==========================================\n",
            "Epoch:  148 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4791666666666665\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.015875017270445824\n",
            "==========================================\n",
            "Epoch:  149 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.480425055928411\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.012166226282715797\n",
            "==========================================\n",
            "Epoch:  150 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.4772222222222218\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.05067061632871628\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  151 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 2.4696467991169975\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.009800971485674381\n",
            "==========================================\n",
            "Epoch:  152 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.464364035087719\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.019528144970536232\n",
            "==========================================\n",
            "Epoch:  153 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.4635076252723307\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.010797233320772648\n",
            "==========================================\n",
            "Epoch:  154 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.4648268398268396\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.026878466829657555\n",
            "==========================================\n",
            "Epoch:  155 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.4725806451612904\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.017440764233469963\n",
            "==========================================\n",
            "Epoch:  156 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.485576923076923\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0021017570979893208\n",
            "==========================================\n",
            "Epoch:  157 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.5047770700636938\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.08177374303340912\n",
            "==========================================\n",
            "Epoch:  158 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.5036919831223625\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.010789958760142326\n",
            "==========================================\n",
            "Epoch:  159 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.506813417190775\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.01840396039187908\n",
            "==========================================\n",
            "Epoch:  160 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: -2.0\n",
            "Mean Reward of that batch -0.5\n",
            "Average Reward of all training: 2.4880208333333336\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.052206069231033325\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  161 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 2.478778467908903\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.06724916398525238\n",
            "==========================================\n",
            "Epoch:  162 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.486111111111111\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.06943105161190033\n",
            "==========================================\n",
            "Epoch:  163 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.491308793456033\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.017215846106410027\n",
            "==========================================\n",
            "Epoch:  164 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.4964430894308944\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.035571739077568054\n",
            "==========================================\n",
            "Epoch:  165 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.511616161616162\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.03392411023378372\n",
            "==========================================\n",
            "Epoch:  166 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 2.508534136546185\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0011185957118868828\n",
            "==========================================\n",
            "Epoch:  167 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.5264471057884235\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.08068147301673889\n",
            "==========================================\n",
            "Epoch:  168 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.521329365079365\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.005675188265740871\n",
            "==========================================\n",
            "Epoch:  169 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 2.514299802761341\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.014849059283733368\n",
            "==========================================\n",
            "Epoch:  170 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 2.50343137254902\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.03549709543585777\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  171 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 2.496588693957115\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.015811920166015625\n",
            "==========================================\n",
            "Epoch:  172 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 2.4878875968992245\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.039621319621801376\n",
            "==========================================\n",
            "Epoch:  173 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 2.4792870905587665\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0218019001185894\n",
            "==========================================\n",
            "Epoch:  174 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 2.4707854406130267\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.031148305162787437\n",
            "==========================================\n",
            "Epoch:  175 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 2.4604761904761907\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.029739322140812874\n",
            "==========================================\n",
            "Epoch:  176 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 3.0\n",
            "Mean Reward of that batch 1.0\n",
            "Average Reward of all training: 2.4521780303030307\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.05098605901002884\n",
            "==========================================\n",
            "Epoch:  177 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.5\n",
            "Average Reward of all training: 2.441148775894539\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.044227611273527145\n",
            "==========================================\n",
            "Epoch:  178 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 2.0\n",
            "Mean Reward of that batch 0.6666666666666666\n",
            "Average Reward of all training: 2.431179775280899\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.08298777788877487\n",
            "==========================================\n",
            "Epoch:  179 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 0.0\n",
            "Mean Reward of that batch 0.0\n",
            "Average Reward of all training: 2.4175977653631286\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.007878612726926804\n",
            "==========================================\n",
            "Epoch:  180 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: -2.0\n",
            "Mean Reward of that batch -0.5\n",
            "Average Reward of all training: 2.401388888888889\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.02534574829041958\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  181 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 1.0\n",
            "Mean Reward of that batch 0.3333333333333333\n",
            "Average Reward of all training: 2.389963167587477\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.003224343294277787\n",
            "==========================================\n",
            "Epoch:  182 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.398809523809524\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.07109985500574112\n",
            "==========================================\n",
            "Epoch:  183 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.410291438979964\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.026143403723835945\n",
            "==========================================\n",
            "Epoch:  184 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.4216485507246377\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.03216806426644325\n",
            "==========================================\n",
            "Epoch:  185 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 2.4436936936936937\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.0539611391723156\n",
            "==========================================\n",
            "Epoch:  186 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.4547491039426523\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.020543981343507767\n",
            "==========================================\n",
            "Epoch:  187 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 2.4790552584670236\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.08624701201915741\n",
            "==========================================\n",
            "Epoch:  188 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.4898049645390072\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.032404158264398575\n",
            "==========================================\n",
            "Epoch:  189 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 2.5110229276895946\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.04783650487661362\n",
            "==========================================\n",
            "Epoch:  190 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.5267543859649124\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.017008842900395393\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  191 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 2.5475567190226878\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.025362564250826836\n",
            "==========================================\n",
            "Epoch:  192 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 2.568142361111111\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.015606553293764591\n",
            "==========================================\n",
            "Epoch:  193 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 2.5936960276338517\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.02186979167163372\n",
            "==========================================\n",
            "Epoch:  194 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 2.616408934707904\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.06053423136472702\n",
            "==========================================\n",
            "Epoch:  195 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.625213675213675\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: -0.1262620985507965\n",
            "==========================================\n",
            "Epoch:  196 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.623724489795918\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.029088856652379036\n",
            "==========================================\n",
            "Epoch:  197 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.618866328257191\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.02301935665309429\n",
            "==========================================\n",
            "Epoch:  198 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 2.614057239057239\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.026726506650447845\n",
            "==========================================\n",
            "Epoch:  199 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.615996649916248\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.019941963255405426\n",
            "==========================================\n",
            "Epoch:  200 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 2.642916666666667\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.04243844375014305\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  201 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.648009950248756\n",
            "Max reward for a batch so far: 16.0\n",
            "Training Loss: 0.024191446602344513\n",
            "==========================================\n",
            "Epoch:  202 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 18.0\n",
            "Mean Reward of that batch 9.0\n",
            "Average Reward of all training: 2.6794554455445545\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05687582865357399\n",
            "==========================================\n",
            "Epoch:  203 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.6777504105090313\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.014838937669992447\n",
            "==========================================\n",
            "Epoch:  204 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.6858660130718954\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.08632680028676987\n",
            "==========================================\n",
            "Epoch:  205 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.6922764227642273\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.15675656497478485\n",
            "==========================================\n",
            "Epoch:  206 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.6937702265372168\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.00589732313528657\n",
            "==========================================\n",
            "Epoch:  207 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.6984702093397748\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.027351805940270424\n",
            "==========================================\n",
            "Epoch:  208 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.711939102564102\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.057605091482400894\n",
            "==========================================\n",
            "Epoch:  209 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 2.7276714513556617\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.17695751786231995\n",
            "==========================================\n",
            "Epoch:  210 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.738492063492063\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05270311236381531\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  211 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.744470774091627\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.010862589813768864\n",
            "==========================================\n",
            "Epoch:  212 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.7574685534591192\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05623186007142067\n",
            "==========================================\n",
            "Epoch:  213 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.7554773082942097\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.18149346113204956\n",
            "==========================================\n",
            "Epoch:  214 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 2.7753115264797508\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.13226531445980072\n",
            "==========================================\n",
            "Epoch:  215 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.785658914728682\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.8244919180870056\n",
            "==========================================\n",
            "Epoch:  216 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.7866512345679015\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.10360533744096756\n",
            "==========================================\n",
            "Epoch:  217 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.794546850998464\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.026332808658480644\n",
            "==========================================\n",
            "Epoch:  218 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.801605504587156\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.00921892561018467\n",
            "==========================================\n",
            "Epoch:  219 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.805555555555556\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.01159206498414278\n",
            "==========================================\n",
            "Epoch:  220 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.810984848484849\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.04328154772520065\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  221 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.8088235294117645\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.1363898515701294\n",
            "==========================================\n",
            "Epoch:  222 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.812687687687688\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.18782855570316315\n",
            "==========================================\n",
            "Epoch:  223 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.816517189835576\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05355766788125038\n",
            "==========================================\n",
            "Epoch:  224 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.824032738095238\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.0993022695183754\n",
            "==========================================\n",
            "Epoch:  225 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.833703703703704\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.03708239644765854\n",
            "==========================================\n",
            "Epoch:  226 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.838864306784661\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.02117576263844967\n",
            "==========================================\n",
            "Epoch:  227 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.8454478707782678\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07325300574302673\n",
            "==========================================\n",
            "Epoch:  228 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.8461257309941526\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0017495928332209587\n",
            "==========================================\n",
            "Epoch:  229 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.8511644832605536\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.06329333037137985\n",
            "==========================================\n",
            "Epoch:  230 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 2.8590579710144928\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.049365390092134476\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  231 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.8683261183261184\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.17207755148410797\n",
            "==========================================\n",
            "Epoch:  232 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.8732040229885056\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05298556387424469\n",
            "==========================================\n",
            "Epoch:  233 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.879470672389127\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.09949517995119095\n",
            "==========================================\n",
            "Epoch:  234 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.8814102564102564\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.036436326801776886\n",
            "==========================================\n",
            "Epoch:  235 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.880496453900709\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04088858515024185\n",
            "==========================================\n",
            "Epoch:  236 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 2.888064971751412\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.014414285309612751\n",
            "==========================================\n",
            "Epoch:  237 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.8990857946554147\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.041219212114810944\n",
            "==========================================\n",
            "Epoch:  238 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.899509803921568\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06749030947685242\n",
            "==========================================\n",
            "Epoch:  239 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.910390516039051\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.12383574992418289\n",
            "==========================================\n",
            "Epoch:  240 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.909375\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.020474113523960114\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  241 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.912517289073306\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.06467542052268982\n",
            "==========================================\n",
            "Epoch:  242 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.917011019283747\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.022657280787825584\n",
            "==========================================\n",
            "Epoch:  243 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.921467764060357\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.009927317500114441\n",
            "==========================================\n",
            "Epoch:  244 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.921789617486339\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.011470794677734375\n",
            "==========================================\n",
            "Epoch:  245 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.923469387755102\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.007845503278076649\n",
            "==========================================\n",
            "Epoch:  246 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 2.930555555555556\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.16147209703922272\n",
            "==========================================\n",
            "Epoch:  247 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.930836707152497\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06926759332418442\n",
            "==========================================\n",
            "Epoch:  248 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.93380376344086\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07924693077802658\n",
            "==========================================\n",
            "Epoch:  249 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 2.944109772423025\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07654789090156555\n",
            "==========================================\n",
            "Epoch:  250 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 2.952333333333333\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.23270577192306519\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  251 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.9538512616201857\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.052144333720207214\n",
            "==========================================\n",
            "Epoch:  252 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.958002645502645\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.099812813103199\n",
            "==========================================\n",
            "Epoch:  253 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.9555335968379444\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06171869486570358\n",
            "==========================================\n",
            "Epoch:  254 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.9570209973753276\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.0248895101249218\n",
            "==========================================\n",
            "Epoch:  255 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.959803921568627\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.08783845603466034\n",
            "==========================================\n",
            "Epoch:  256 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 2.9658203125\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.14002986252307892\n",
            "==========================================\n",
            "Epoch:  257 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.9711413748378726\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0022591392043977976\n",
            "==========================================\n",
            "Epoch:  258 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 2.97125322997416\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.030559569597244263\n",
            "==========================================\n",
            "Epoch:  259 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.975225225225225\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.10731255263090134\n",
            "==========================================\n",
            "Epoch:  260 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 2.9791666666666665\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.5425671339035034\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  261 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.9766922094508295\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07063159346580505\n",
            "==========================================\n",
            "Epoch:  262 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.974236641221374\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.023571781814098358\n",
            "==========================================\n",
            "Epoch:  263 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.9756020278833963\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07852549850940704\n",
            "==========================================\n",
            "Epoch:  264 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.98074494949495\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05997542664408684\n",
            "==========================================\n",
            "Epoch:  265 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.982075471698113\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06580448150634766\n",
            "==========================================\n",
            "Epoch:  266 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.983395989974937\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.22440195083618164\n",
            "==========================================\n",
            "Epoch:  267 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 2.9822097378277155\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03763628378510475\n",
            "==========================================\n",
            "Epoch:  268 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 2.97978855721393\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.008575466461479664\n",
            "==========================================\n",
            "Epoch:  269 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 2.9885377942998765\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.051434729248285294\n",
            "==========================================\n",
            "Epoch:  270 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 2.9898148148148147\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05123438313603401\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  271 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 2.994772447724477\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.016742682084441185\n",
            "==========================================\n",
            "Epoch:  272 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 2.9972426470588234\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.048507314175367355\n",
            "==========================================\n",
            "Epoch:  273 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.0045787545787546\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04441863298416138\n",
            "==========================================\n",
            "Epoch:  274 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.0045620437956204\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.026988286525011063\n",
            "==========================================\n",
            "Epoch:  275 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.0118181818181817\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.035565588623285294\n",
            "==========================================\n",
            "Epoch:  276 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.0166062801932365\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.2680431306362152\n",
            "==========================================\n",
            "Epoch:  277 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.0165463297232247\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.1400575488805771\n",
            "==========================================\n",
            "Epoch:  278 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.018884892086331\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06795565038919449\n",
            "==========================================\n",
            "Epoch:  279 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.0176224611708484\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04062225669622421\n",
            "==========================================\n",
            "Epoch:  280 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.019940476190476\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04910758137702942\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  281 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.0269869513641754\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.1719459444284439\n",
            "==========================================\n",
            "Epoch:  282 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.0316193853427893\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.02870980091392994\n",
            "==========================================\n",
            "Epoch:  283 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.0456419316843344\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.02226555347442627\n",
            "==========================================\n",
            "Epoch:  284 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.0466549295774645\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.00013770186342298985\n",
            "==========================================\n",
            "Epoch:  285 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.0464912280701753\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06777279824018478\n",
            "==========================================\n",
            "Epoch:  286 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 3.0428321678321675\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.012228845618665218\n",
            "==========================================\n",
            "Epoch:  287 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.051393728222996\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.05595344305038452\n",
            "==========================================\n",
            "Epoch:  288 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.048900462962963\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.025909025222063065\n",
            "==========================================\n",
            "Epoch:  289 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.053921568627451\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.08714380860328674\n",
            "==========================================\n",
            "Epoch:  290 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.05603448275862\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.028966380283236504\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  291 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.0558419243986252\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04383928328752518\n",
            "==========================================\n",
            "Epoch:  292 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.0607876712328763\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.0879862830042839\n",
            "==========================================\n",
            "Epoch:  293 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.0639931740614332\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.032159384340047836\n",
            "==========================================\n",
            "Epoch:  294 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.0722789115646254\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.08506197482347488\n",
            "==========================================\n",
            "Epoch:  295 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.077118644067796\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.11493798345327377\n",
            "==========================================\n",
            "Epoch:  296 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.0813626126126126\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.0038917898200452328\n",
            "==========================================\n",
            "Epoch:  297 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.0878226711560046\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.006615704391151667\n",
            "==========================================\n",
            "Epoch:  298 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.09423937360179\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.042419858276844025\n",
            "==========================================\n",
            "Epoch:  299 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 3.108974358974359\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.020475352182984352\n",
            "==========================================\n",
            "Epoch:  300 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.1075\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0206347294151783\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  301 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.106035437430786\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.01154976338148117\n",
            "==========================================\n",
            "Epoch:  302 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.104580573951435\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0009875299874693155\n",
            "==========================================\n",
            "Epoch:  303 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.111936193619362\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.05445045232772827\n",
            "==========================================\n",
            "Epoch:  304 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.1126644736842106\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.03449847176671028\n",
            "==========================================\n",
            "Epoch:  305 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 3.5\n",
            "Average Reward of all training: 3.113934426229508\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.05601228028535843\n",
            "==========================================\n",
            "Epoch:  306 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.113562091503268\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.009408923797309399\n",
            "==========================================\n",
            "Epoch:  307 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 3.1099348534201954\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04335447773337364\n",
            "==========================================\n",
            "Epoch:  308 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.1095779220779223\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.025929445400834084\n",
            "==========================================\n",
            "Epoch:  309 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.108144552319309\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.007565012667328119\n",
            "==========================================\n",
            "Epoch:  310 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.1088709677419355\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.014039025641977787\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  311 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 3.5\n",
            "Average Reward of all training: 3.110128617363344\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.029125044122338295\n",
            "==========================================\n",
            "Epoch:  312 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.112980769230769\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0074554504826664925\n",
            "==========================================\n",
            "Epoch:  313 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.115814696485623\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.016873611137270927\n",
            "==========================================\n",
            "Epoch:  314 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.1175690021231426\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.030811632052063942\n",
            "==========================================\n",
            "Epoch:  315 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.1246031746031746\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.028988488018512726\n",
            "==========================================\n",
            "Epoch:  316 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.132120253164557\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03535015136003494\n",
            "==========================================\n",
            "Epoch:  317 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.1338065194532074\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.09190589934587479\n",
            "==========================================\n",
            "Epoch:  318 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.1354821802935007\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06714477390050888\n",
            "==========================================\n",
            "Epoch:  319 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.134012539184953\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.023955602198839188\n",
            "==========================================\n",
            "Epoch:  320 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.13828125\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.046615906059741974\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  321 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.1440809968847354\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.10831424593925476\n",
            "==========================================\n",
            "Epoch:  322 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.145703933747412\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.010619807057082653\n",
            "==========================================\n",
            "Epoch:  323 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.1514447884416925\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.06025444343686104\n",
            "==========================================\n",
            "Epoch:  324 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.1550925925925926\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.024340519681572914\n",
            "==========================================\n",
            "Epoch:  325 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.1546153846153846\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04517649859189987\n",
            "==========================================\n",
            "Epoch:  326 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.1587423312883436\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0072553749196231365\n",
            "==========================================\n",
            "Epoch:  327 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.16335372069317\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05105740576982498\n",
            "==========================================\n",
            "Epoch:  328 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.167936991869919\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.01624532788991928\n",
            "==========================================\n",
            "Epoch:  329 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.173505572441743\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.01499084196984768\n",
            "==========================================\n",
            "Epoch:  330 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.175\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.003388182260096073\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  331 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.18202416918429\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.05714061111211777\n",
            "==========================================\n",
            "Epoch:  332 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 3.1965361445783134\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.037356819957494736\n",
            "==========================================\n",
            "Epoch:  333 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.2004504504504503\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03957022354006767\n",
            "==========================================\n",
            "Epoch:  334 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.2058383233532934\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.015131651423871517\n",
            "==========================================\n",
            "Epoch:  335 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.206218905472637\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03856853023171425\n",
            "==========================================\n",
            "Epoch:  336 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.2105654761904763\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.06957598030567169\n",
            "==========================================\n",
            "Epoch:  337 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.208951533135509\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.02433832921087742\n",
            "==========================================\n",
            "Epoch:  338 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.206360946745562\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.019957849755883217\n",
            "==========================================\n",
            "Epoch:  339 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.2057522123893807\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.004081714432686567\n",
            "==========================================\n",
            "Epoch:  340 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.211029411764706\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07457025349140167\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  341 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.215298142717497\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.02955685742199421\n",
            "==========================================\n",
            "Epoch:  342 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.2166179337231973\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.01794942282140255\n",
            "==========================================\n",
            "Epoch:  343 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.223275024295433\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.03385479003190994\n",
            "==========================================\n",
            "Epoch:  344 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.2226259689922485\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.015760304406285286\n",
            "==========================================\n",
            "Epoch:  345 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.2277777777777783\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.020111698657274246\n",
            "==========================================\n",
            "Epoch:  346 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.2386801541425823\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.04326232895255089\n",
            "==========================================\n",
            "Epoch:  347 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.2466378482228633\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.009645065292716026\n",
            "==========================================\n",
            "Epoch:  348 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.2507183908045976\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.28883877396583557\n",
            "==========================================\n",
            "Epoch:  349 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.2509551098376317\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.027368221431970596\n",
            "==========================================\n",
            "Epoch:  350 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.249285714285714\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.02549874782562256\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  351 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.2466761633428303\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.030348746106028557\n",
            "==========================================\n",
            "Epoch:  352 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.2469223484848486\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03304993733763695\n",
            "==========================================\n",
            "Epoch:  353 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.2443342776203967\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.008304291404783726\n",
            "==========================================\n",
            "Epoch:  354 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.244585687382298\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.027002917602658272\n",
            "==========================================\n",
            "Epoch:  355 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.243896713615024\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.021448642015457153\n",
            "==========================================\n",
            "Epoch:  356 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.2432116104868918\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0298935417085886\n",
            "==========================================\n",
            "Epoch:  357 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.2443977591036415\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.025053881108760834\n",
            "==========================================\n",
            "Epoch:  358 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.252094972067039\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06337453424930573\n",
            "==========================================\n",
            "Epoch:  359 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.2583565459610027\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.29978877305984497\n",
            "==========================================\n",
            "Epoch:  360 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.261342592592593\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.021349266171455383\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  361 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.266158818097877\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0407191663980484\n",
            "==========================================\n",
            "Epoch:  362 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.263581952117864\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.031934041529893875\n",
            "==========================================\n",
            "Epoch:  363 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.2702020202020208\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.026088574901223183\n",
            "==========================================\n",
            "Epoch:  364 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.274954212454213\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.01381316315382719\n",
            "==========================================\n",
            "Epoch:  365 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 3.5\n",
            "Average Reward of all training: 3.2755707762557082\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.019567444920539856\n",
            "==========================================\n",
            "Epoch:  366 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.2802823315118403\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.06820567697286606\n",
            "==========================================\n",
            "Epoch:  367 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.284059945504087\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.011402995325624943\n",
            "==========================================\n",
            "Epoch:  368 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.2832880434782608\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03693491593003273\n",
            "==========================================\n",
            "Epoch:  369 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.287037037037037\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.02689538709819317\n",
            "==========================================\n",
            "Epoch:  370 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.2871621621621623\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.011982056312263012\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  371 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.2890835579514826\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.010259435512125492\n",
            "==========================================\n",
            "Epoch:  372 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.2936827956989245\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.004372942727059126\n",
            "==========================================\n",
            "Epoch:  373 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.295576407506702\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.07010164856910706\n",
            "==========================================\n",
            "Epoch:  374 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.293003565062389\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.01701432466506958\n",
            "==========================================\n",
            "Epoch:  375 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.2948888888888894\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.021518565714359283\n",
            "==========================================\n",
            "Epoch:  376 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.293218085106383\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.02732083573937416\n",
            "==========================================\n",
            "Epoch:  377 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.292440318302387\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.019320975989103317\n",
            "==========================================\n",
            "Epoch:  378 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.293430335097002\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0422435998916626\n",
            "==========================================\n",
            "Epoch:  379 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.2992524186455587\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.039486221969127655\n",
            "==========================================\n",
            "Epoch:  380 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.303728070175439\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.006549116224050522\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  381 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.3029308836395455\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.008186191320419312\n",
            "==========================================\n",
            "Epoch:  382 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.3012652705061085\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.007506067398935556\n",
            "==========================================\n",
            "Epoch:  383 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.298738033072237\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.03058028034865856\n",
            "==========================================\n",
            "Epoch:  384 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.297960069444444\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.02262389473617077\n",
            "==========================================\n",
            "Epoch:  385 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.2997835497835495\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.036268200725317\n",
            "==========================================\n",
            "Epoch:  386 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 3.296416234887737\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.00029023035313002765\n",
            "==========================================\n",
            "Epoch:  387 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.2947889750215333\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.026035957038402557\n",
            "==========================================\n",
            "Epoch:  388 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.300472508591066\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.021551912650465965\n",
            "==========================================\n",
            "Epoch:  389 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.2979862896315333\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.0015163159696385264\n",
            "==========================================\n",
            "Epoch:  390 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.3006410256410255\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.00849628634750843\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  391 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.3024296675191818\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.011778496205806732\n",
            "==========================================\n",
            "Epoch:  392 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.3105867346938775\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.02849051170051098\n",
            "==========================================\n",
            "Epoch:  393 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.3123409669211195\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.10017906874418259\n",
            "==========================================\n",
            "Epoch:  394 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.31577834179357\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0618072971701622\n",
            "==========================================\n",
            "Epoch:  395 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.3187763713080165\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.07935145497322083\n",
            "==========================================\n",
            "Epoch:  396 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.322180134680135\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.0820290744304657\n",
            "==========================================\n",
            "Epoch:  397 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.326406381192276\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.010421166196465492\n",
            "==========================================\n",
            "Epoch:  398 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.3306113902847576\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: 0.15241694450378418\n",
            "==========================================\n",
            "Epoch:  399 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.3331244778613196\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.09366133064031601\n",
            "==========================================\n",
            "Epoch:  400 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.3410416666666665\n",
            "Max reward for a batch so far: 18.0\n",
            "Training Loss: -0.10688420385122299\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  401 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 19.0\n",
            "Mean Reward of that batch 6.333333333333333\n",
            "Average Reward of all training: 3.348503740648379\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.016116177663207054\n",
            "==========================================\n",
            "Epoch:  402 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.353855721393035\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07644981890916824\n",
            "==========================================\n",
            "Epoch:  403 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.356699751861042\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.072167307138443\n",
            "==========================================\n",
            "Epoch:  404 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.3657178217821784\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08468356728553772\n",
            "==========================================\n",
            "Epoch:  405 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.3685185185185187\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.076922208070755\n",
            "==========================================\n",
            "Epoch:  406 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.3713054187192117\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.016375811770558357\n",
            "==========================================\n",
            "Epoch:  407 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.3753071253071254\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.022387536242604256\n",
            "==========================================\n",
            "Epoch:  408 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.380514705882353\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.002340446226298809\n",
            "==========================================\n",
            "Epoch:  409 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.3844743276283618\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.004218342714011669\n",
            "==========================================\n",
            "Epoch:  410 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.3859756097560973\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0539570190012455\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  411 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.389091646390917\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.020005734637379646\n",
            "==========================================\n",
            "Epoch:  412 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.395428802588997\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.01456078514456749\n",
            "==========================================\n",
            "Epoch:  413 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.399313962873285\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.004150692839175463\n",
            "==========================================\n",
            "Epoch:  414 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.40438808373591\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.004103074781596661\n",
            "==========================================\n",
            "Epoch:  415 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.4066265060240966\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.00642967876046896\n",
            "==========================================\n",
            "Epoch:  416 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.415264423076923\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10390935093164444\n",
            "==========================================\n",
            "Epoch:  417 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.415067945643485\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.004450942389667034\n",
            "==========================================\n",
            "Epoch:  418 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.4140749601275915\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.029962841421365738\n",
            "==========================================\n",
            "Epoch:  419 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.4202466189339695\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.036809761077165604\n",
            "==========================================\n",
            "Epoch:  420 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.427579365079365\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.025379754602909088\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  421 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.432501979414093\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.09884908050298691\n",
            "==========================================\n",
            "Epoch:  422 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.4338467614533963\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.016263119876384735\n",
            "==========================================\n",
            "Epoch:  423 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.435185185185185\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.027038630098104477\n",
            "==========================================\n",
            "Epoch:  424 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.433372641509434\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.010645898059010506\n",
            "==========================================\n",
            "Epoch:  425 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.4331372549019608\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.015364712104201317\n",
            "==========================================\n",
            "Epoch:  426 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 3.4297730829420967\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.00042944023152813315\n",
            "==========================================\n",
            "Epoch:  427 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.432279469164715\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.014615826308727264\n",
            "==========================================\n",
            "Epoch:  428 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 18.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.438278816199377\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.02584642730653286\n",
            "==========================================\n",
            "Epoch:  429 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.438034188034188\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.022489959374070168\n",
            "==========================================\n",
            "Epoch:  430 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.440503875968992\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.02018461748957634\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  431 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.4418020108275327\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.01487954705953598\n",
            "==========================================\n",
            "Epoch:  432 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.443094135802469\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.025336697697639465\n",
            "==========================================\n",
            "Epoch:  433 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.4436104695919942\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.021360110491514206\n",
            "==========================================\n",
            "Epoch:  434 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.4483486943164365\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.02242521569132805\n",
            "==========================================\n",
            "Epoch:  435 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.4496168582375484\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.06451887637376785\n",
            "==========================================\n",
            "Epoch:  436 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.454319571865444\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.012621027417480946\n",
            "==========================================\n",
            "Epoch:  437 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.4548054919908466\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.016688121482729912\n",
            "==========================================\n",
            "Epoch:  438 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.459474885844749\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.014659945853054523\n",
            "==========================================\n",
            "Epoch:  439 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.4591875474563407\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03921361640095711\n",
            "==========================================\n",
            "Epoch:  440 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.460416666666667\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.025486662983894348\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  441 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.459372637944067\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.045916903764009476\n",
            "==========================================\n",
            "Epoch:  442 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.4605957767722475\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.020921269431710243\n",
            "==========================================\n",
            "Epoch:  443 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.4640707298720845\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03065541759133339\n",
            "==========================================\n",
            "Epoch:  444 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.4709084084084085\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.031539514660835266\n",
            "==========================================\n",
            "Epoch:  445 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.4743445692883896\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.056611351668834686\n",
            "==========================================\n",
            "Epoch:  446 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.4725336322869955\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.015558021143078804\n",
            "==========================================\n",
            "Epoch:  447 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.4722222222222228\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.02126668579876423\n",
            "==========================================\n",
            "Epoch:  448 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.4745163690476195\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.021001046523451805\n",
            "==========================================\n",
            "Epoch:  449 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.4812546399406092\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.11691900342702866\n",
            "==========================================\n",
            "Epoch:  450 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.48462962962963\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22691987454891205\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  451 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.4820768662232076\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.022319212555885315\n",
            "==========================================\n",
            "Epoch:  452 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.4795353982300883\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.18489664793014526\n",
            "==========================================\n",
            "Epoch:  453 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.4777409860191315\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.025499548763036728\n",
            "==========================================\n",
            "Epoch:  454 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.4766886930983842\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05607842281460762\n",
            "==========================================\n",
            "Epoch:  455 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.4756410256410253\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.005749555304646492\n",
            "==========================================\n",
            "Epoch:  456 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.4738669590643276\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.032200198620557785\n",
            "==========================================\n",
            "Epoch:  457 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.4761123267687823\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04625752195715904\n",
            "==========================================\n",
            "Epoch:  458 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.4783478893740907\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0024355128407478333\n",
            "==========================================\n",
            "Epoch:  459 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.4780319535221498\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.11907653510570526\n",
            "==========================================\n",
            "Epoch:  460 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.4769927536231884\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.010863367468118668\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  461 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.4795733911785978\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.09761866182088852\n",
            "==========================================\n",
            "Epoch:  462 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.482142857142857\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09761356562376022\n",
            "==========================================\n",
            "Epoch:  463 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.4839812814974804\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.12508611381053925\n",
            "==========================================\n",
            "Epoch:  464 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.4872485632183907\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.11123738437891006\n",
            "==========================================\n",
            "Epoch:  465 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.4919354838709675\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04994148388504982\n",
            "==========================================\n",
            "Epoch:  466 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.496244635193133\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.018501602113246918\n",
            "==========================================\n",
            "Epoch:  467 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.4987508922198427\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.013292756862938404\n",
            "==========================================\n",
            "Epoch:  468 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.499109686609686\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.022209402173757553\n",
            "==========================================\n",
            "Epoch:  469 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.5012437810945265\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03636574372649193\n",
            "==========================================\n",
            "Epoch:  470 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.5076241134751767\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05532572790980339\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  471 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.508669497523\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03133397176861763\n",
            "==========================================\n",
            "Epoch:  472 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.5097104519774005\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.00317938975058496\n",
            "==========================================\n",
            "Epoch:  473 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 8.5\n",
            "Average Reward of all training: 3.5202607470049325\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05533107742667198\n",
            "==========================================\n",
            "Epoch:  474 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.5247890295358646\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.09644147753715515\n",
            "==========================================\n",
            "Epoch:  475 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.528947368421052\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05969373136758804\n",
            "==========================================\n",
            "Epoch:  476 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.5330882352941173\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.06332893669605255\n",
            "==========================================\n",
            "Epoch:  477 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.5403563941299785\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06477787345647812\n",
            "==========================================\n",
            "Epoch:  478 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.5427126917712686\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.037616487592458725\n",
            "==========================================\n",
            "Epoch:  479 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.5422755741127343\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.02694491669535637\n",
            "==========================================\n",
            "Epoch:  480 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.5453125\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.02519785612821579\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  481 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.5472972972972974\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.02025976963341236\n",
            "==========================================\n",
            "Epoch:  482 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.5516943291839556\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05865968018770218\n",
            "==========================================\n",
            "Epoch:  483 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.5505521048999307\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.05883454903960228\n",
            "==========================================\n",
            "Epoch:  484 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.5507920110192837\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.007953451946377754\n",
            "==========================================\n",
            "Epoch:  485 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.553780068728522\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.05222681164741516\n",
            "==========================================\n",
            "Epoch:  486 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.555384087791495\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.010798031464219093\n",
            "==========================================\n",
            "Epoch:  487 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.5583504449007526\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1056165024638176\n",
            "==========================================\n",
            "Epoch:  488 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.5623292349726774\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06495995819568634\n",
            "==========================================\n",
            "Epoch:  489 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.561179277436946\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03083467297255993\n",
            "==========================================\n",
            "Epoch:  490 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.563095238095238\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03872567415237427\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  491 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.56704005431093\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04853654280304909\n",
            "==========================================\n",
            "Epoch:  492 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.5658875338753386\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07250391691923141\n",
            "==========================================\n",
            "Epoch:  493 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.5647396889790395\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.011937844567000866\n",
            "==========================================\n",
            "Epoch:  494 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.5649460188933872\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.004471156746149063\n",
            "==========================================\n",
            "Epoch:  495 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 2.75\n",
            "Average Reward of all training: 3.563299663299663\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1212754175066948\n",
            "==========================================\n",
            "Epoch:  496 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.5621639784946235\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05543237179517746\n",
            "==========================================\n",
            "Epoch:  497 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.5650570087189806\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.028930112719535828\n",
            "==========================================\n",
            "Epoch:  498 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.57095046854083\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09616538882255554\n",
            "==========================================\n",
            "Epoch:  499 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.57314629258517\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.12285266816616058\n",
            "==========================================\n",
            "Epoch:  500 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.5766666666666667\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03775372728705406\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  501 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.579507651363939\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.050140589475631714\n",
            "==========================================\n",
            "Epoch:  502 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.579681274900398\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04688463360071182\n",
            "==========================================\n",
            "Epoch:  503 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.579191517561299\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.14370815455913544\n",
            "==========================================\n",
            "Epoch:  504 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.5806878306878303\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1390916258096695\n",
            "==========================================\n",
            "Epoch:  505 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.580858085808581\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.14027932286262512\n",
            "==========================================\n",
            "Epoch:  506 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.584650856389987\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.10546794533729553\n",
            "==========================================\n",
            "Epoch:  507 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.5880999342537807\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.020524565130472183\n",
            "==========================================\n",
            "Epoch:  508 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.5928477690288716\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.7448943853378296\n",
            "==========================================\n",
            "Epoch:  509 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.592992796332678\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06839385628700256\n",
            "==========================================\n",
            "Epoch:  510 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.592483660130719\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03707372024655342\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  511 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.594259621656882\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08251533657312393\n",
            "==========================================\n",
            "Epoch:  512 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.597005208333333\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1123361811041832\n",
            "==========================================\n",
            "Epoch:  513 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 3.5938921377517867\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07376467436552048\n",
            "==========================================\n",
            "Epoch:  514 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.599546044098573\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03344090282917023\n",
            "==========================================\n",
            "Epoch:  515 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.601294498381877\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05160290375351906\n",
            "==========================================\n",
            "Epoch:  516 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.604005167958656\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.08023303747177124\n",
            "==========================================\n",
            "Epoch:  517 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.6054158607350097\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10671207308769226\n",
            "==========================================\n",
            "Epoch:  518 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.61003861003861\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.10729891806840897\n",
            "==========================================\n",
            "Epoch:  519 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.6146435452793835\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2022661417722702\n",
            "==========================================\n",
            "Epoch:  520 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.6182692307692306\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.18191903829574585\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  521 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.624760076775432\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.13900279998779297\n",
            "==========================================\n",
            "Epoch:  522 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.628352490421456\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.034656938165426254\n",
            "==========================================\n",
            "Epoch:  523 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 5.0\n",
            "Mean Reward of that batch 1.6666666666666667\n",
            "Average Reward of all training: 3.624601657106437\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07083189487457275\n",
            "==========================================\n",
            "Epoch:  524 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.6234096692111954\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08603263646364212\n",
            "==========================================\n",
            "Epoch:  525 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 3.619047619047619\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1363077461719513\n",
            "==========================================\n",
            "Epoch:  526 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.6216730038022815\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.12547914683818817\n",
            "==========================================\n",
            "Epoch:  527 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.6261859582542693\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.17390042543411255\n",
            "==========================================\n",
            "Epoch:  528 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.6287878787878793\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08854831755161285\n",
            "==========================================\n",
            "Epoch:  529 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.6320100819155643\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10315205901861191\n",
            "==========================================\n",
            "Epoch:  530 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.6339622641509437\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.17696799337863922\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  531 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.637476459510358\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09123624116182327\n",
            "==========================================\n",
            "Epoch:  532 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.6412907268170427\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.274191290140152\n",
            "==========================================\n",
            "Epoch:  533 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.6432145090681685\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.10959342122077942\n",
            "==========================================\n",
            "Epoch:  534 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.6438826466916363\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0469287745654583\n",
            "==========================================\n",
            "Epoch:  535 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.6454828660436145\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.01125479768961668\n",
            "==========================================\n",
            "Epoch:  536 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.648009950248756\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.5188096165657043\n",
            "==========================================\n",
            "Epoch:  537 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.649286157666046\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03507310152053833\n",
            "==========================================\n",
            "Epoch:  538 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.649938042131351\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06976082921028137\n",
            "==========================================\n",
            "Epoch:  539 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.650587507730365\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.015111293643712997\n",
            "==========================================\n",
            "Epoch:  540 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.6558641975308643\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.037731289863586426\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  541 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.6583487369069627\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1358516961336136\n",
            "==========================================\n",
            "Epoch:  542 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.6617466174661746\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.12785997986793518\n",
            "==========================================\n",
            "Epoch:  543 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.6660527931246163\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03208235651254654\n",
            "==========================================\n",
            "Epoch:  544 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.6691176470588234\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.008247043937444687\n",
            "==========================================\n",
            "Epoch:  545 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.672782874617737\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.02690749615430832\n",
            "==========================================\n",
            "Epoch:  546 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.671550671550672\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.06725826114416122\n",
            "==========================================\n",
            "Epoch:  547 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.6733698964046315\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06356310844421387\n",
            "==========================================\n",
            "Epoch:  548 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.6721411192214113\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.00934203714132309\n",
            "==========================================\n",
            "Epoch:  549 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.6721311475409837\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.054567620158195496\n",
            "==========================================\n",
            "Epoch:  550 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.6739393939393943\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05798777565360069\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  551 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.676346037507562\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.01130672823637724\n",
            "==========================================\n",
            "Epoch:  552 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.6751207729468596\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04065887629985809\n",
            "==========================================\n",
            "Epoch:  553 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.678119349005425\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.06893470883369446\n",
            "==========================================\n",
            "Epoch:  554 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 3.675090252707581\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.13805721700191498\n",
            "==========================================\n",
            "Epoch:  555 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.6750750750750747\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.016355907544493675\n",
            "==========================================\n",
            "Epoch:  556 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.6774580335731413\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.009899496100842953\n",
            "==========================================\n",
            "Epoch:  557 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.6774386594853374\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0869172140955925\n",
            "==========================================\n",
            "Epoch:  558 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.6774193548387095\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.11477554589509964\n",
            "==========================================\n",
            "Epoch:  559 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.6785927251043526\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10734709352254868\n",
            "==========================================\n",
            "Epoch:  560 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.6767857142857143\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0897921472787857\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  561 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.6797385620915026\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1366751790046692\n",
            "==========================================\n",
            "Epoch:  562 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.682087781731909\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08245600759983063\n",
            "==========================================\n",
            "Epoch:  563 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.682652457075192\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10039418935775757\n",
            "==========================================\n",
            "Epoch:  564 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.680260047281323\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.421145498752594\n",
            "==========================================\n",
            "Epoch:  565 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.6825958702064887\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.21475638449192047\n",
            "==========================================\n",
            "Epoch:  566 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.6849234393403996\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0818149670958519\n",
            "==========================================\n",
            "Epoch:  567 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.6907701352145788\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03984459117054939\n",
            "==========================================\n",
            "Epoch:  568 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.695715962441315\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.33069679141044617\n",
            "==========================================\n",
            "Epoch:  569 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.696836555360281\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.018049344420433044\n",
            "==========================================\n",
            "Epoch:  570 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.7\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.34011319279670715\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  571 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 8.5\n",
            "Average Reward of all training: 3.7084063047285465\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.029295247048139572\n",
            "==========================================\n",
            "Epoch:  572 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.7097902097902096\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22429507970809937\n",
            "==========================================\n",
            "Epoch:  573 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.7155322862129143\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.03587140142917633\n",
            "==========================================\n",
            "Epoch:  574 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.7195121951219514\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.05441150441765785\n",
            "==========================================\n",
            "Epoch:  575 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.7182608695652175\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.24653419852256775\n",
            "==========================================\n",
            "Epoch:  576 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.7213541666666665\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.060738455504179\n",
            "==========================================\n",
            "Epoch:  577 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.7212593876372044\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.12576010823249817\n",
            "==========================================\n",
            "Epoch:  578 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.7243367935409464\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.022039012983441353\n",
            "==========================================\n",
            "Epoch:  579 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.727403569372482\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0967586487531662\n",
            "==========================================\n",
            "Epoch:  580 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.730459770114943\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.2577613592147827\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  581 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.7343660355708552\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07701219618320465\n",
            "==========================================\n",
            "Epoch:  582 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.737399770904926\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.3117337226867676\n",
            "==========================================\n",
            "Epoch:  583 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.74128073184677\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.06443744152784348\n",
            "==========================================\n",
            "Epoch:  584 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.743436073059361\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.005456746555864811\n",
            "==========================================\n",
            "Epoch:  585 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.746723646723646\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04463125392794609\n",
            "==========================================\n",
            "Epoch:  586 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.74971558589306\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.3127545118331909\n",
            "==========================================\n",
            "Epoch:  587 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.751845542305508\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.15568570792675018\n",
            "==========================================\n",
            "Epoch:  588 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.752834467120182\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.030119111761450768\n",
            "==========================================\n",
            "Epoch:  589 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.7583474816072444\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0956299751996994\n",
            "==========================================\n",
            "Epoch:  590 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.763841807909605\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.23100639879703522\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  591 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.768471517202482\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03244346007704735\n",
            "==========================================\n",
            "Epoch:  592 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.7713963963963963\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.006934299599379301\n",
            "==========================================\n",
            "Epoch:  593 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.773468240584598\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1626928299665451\n",
            "==========================================\n",
            "Epoch:  594 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.776094276094276\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.7606441974639893\n",
            "==========================================\n",
            "Epoch:  595 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.7747899159663865\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0048269955441355705\n",
            "==========================================\n",
            "Epoch:  596 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.777684563758389\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.11788659542798996\n",
            "==========================================\n",
            "Epoch:  597 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.7797319932998326\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.07407841831445694\n",
            "==========================================\n",
            "Epoch:  598 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.7851170568561874\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.017677683383226395\n",
            "==========================================\n",
            "Epoch:  599 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.787145242070117\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.013106481172144413\n",
            "==========================================\n",
            "Epoch:  600 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.7863888888888892\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.14024396240711212\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  601 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 18.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.7900721020521355\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09884185343980789\n",
            "==========================================\n",
            "Epoch:  602 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.790974529346622\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22807630896568298\n",
            "==========================================\n",
            "Epoch:  603 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.7929795467108898\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0024889849592000246\n",
            "==========================================\n",
            "Epoch:  604 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.7938741721854305\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.15025857090950012\n",
            "==========================================\n",
            "Epoch:  605 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.794765840220386\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.029068076983094215\n",
            "==========================================\n",
            "Epoch:  606 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.7951045104510452\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2219528704881668\n",
            "==========================================\n",
            "Epoch:  607 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.7995606809445364\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04863252118229866\n",
            "==========================================\n",
            "Epoch:  608 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.799342105263158\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.18751025199890137\n",
            "==========================================\n",
            "Epoch:  609 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.79912424740011\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.008528520353138447\n",
            "==========================================\n",
            "Epoch:  610 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.800546448087432\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1780293881893158\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  611 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.8049645390070923\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0651685893535614\n",
            "==========================================\n",
            "Epoch:  612 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.80582788671024\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.043694205582141876\n",
            "==========================================\n",
            "Epoch:  613 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.8056008700380644\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2512055039405823\n",
            "==========================================\n",
            "Epoch:  614 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.804831704668839\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04740826040506363\n",
            "==========================================\n",
            "Epoch:  615 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.8059620596205965\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.167634978890419\n",
            "==========================================\n",
            "Epoch:  616 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.8084415584415585\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0743701159954071\n",
            "==========================================\n",
            "Epoch:  617 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.808211777417612\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07014579325914383\n",
            "==========================================\n",
            "Epoch:  618 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.8096008629989213\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09613359719514847\n",
            "==========================================\n",
            "Epoch:  619 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8099084544965\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0009551523835398257\n",
            "==========================================\n",
            "Epoch:  620 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.810215053763441\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1093270480632782\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  621 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.8078368223295755\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.05942368507385254\n",
            "==========================================\n",
            "Epoch:  622 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.809217577706324\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.028008224442601204\n",
            "==========================================\n",
            "Epoch:  623 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.810326377742108\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.17046132683753967\n",
            "==========================================\n",
            "Epoch:  624 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.81116452991453\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.441805899143219\n",
            "==========================================\n",
            "Epoch:  625 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.8125333333333327\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.11661028861999512\n",
            "==========================================\n",
            "Epoch:  626 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.8101703940362084\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.034206733107566833\n",
            "==========================================\n",
            "Epoch:  627 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8104731525784157\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.14946842193603516\n",
            "==========================================\n",
            "Epoch:  628 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.8091825902335454\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.08499888330698013\n",
            "==========================================\n",
            "Epoch:  629 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.8084260731319555\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.030650019645690918\n",
            "==========================================\n",
            "Epoch:  630 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.8095238095238093\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06734268367290497\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  631 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.814580031695721\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.18053612112998962\n",
            "==========================================\n",
            "Epoch:  632 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.8180379746835444\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.352191299200058\n",
            "==========================================\n",
            "Epoch:  633 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8199052132701423\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0017760974587872624\n",
            "==========================================\n",
            "Epoch:  634 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.819663512092535\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.19787098467350006\n",
            "==========================================\n",
            "Epoch:  635 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.820472440944882\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.18273165822029114\n",
            "==========================================\n",
            "Epoch:  636 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8207547169811322\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08490899205207825\n",
            "==========================================\n",
            "Epoch:  637 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8226059654631084\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.22044190764427185\n",
            "==========================================\n",
            "Epoch:  638 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.823406478578893\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.21935249865055084\n",
            "==========================================\n",
            "Epoch:  639 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.8231611893583723\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04285542294383049\n",
            "==========================================\n",
            "Epoch:  640 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.8239583333333327\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.06267353892326355\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  641 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8257930317212683\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1641462743282318\n",
            "==========================================\n",
            "Epoch:  642 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.8271028037383177\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04256707429885864\n",
            "==========================================\n",
            "Epoch:  643 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.82789009849663\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.060605503618717194\n",
            "==========================================\n",
            "Epoch:  644 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.829192546583851\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.08668608218431473\n",
            "==========================================\n",
            "Epoch:  645 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.8289405684754527\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.001980904256924987\n",
            "==========================================\n",
            "Epoch:  646 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.833849329205367\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.184248149394989\n",
            "==========================================\n",
            "Epoch:  647 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 3.8366821226172076\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.11736542731523514\n",
            "==========================================\n",
            "Epoch:  648 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 4.0\n",
            "Mean Reward of that batch 1.3333333333333333\n",
            "Average Reward of all training: 3.832818930041152\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.277980238199234\n",
            "==========================================\n",
            "Epoch:  649 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.833076527991782\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1600707471370697\n",
            "==========================================\n",
            "Epoch:  650 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.832307692307692\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.16828198730945587\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  651 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.834101382488479\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.17058098316192627\n",
            "==========================================\n",
            "Epoch:  652 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.8328220858895707\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.14327937364578247\n",
            "==========================================\n",
            "Epoch:  653 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.833843797856049\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.31806790828704834\n",
            "==========================================\n",
            "Epoch:  654 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 3.8394495412844036\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.0889461487531662\n",
            "==========================================\n",
            "Epoch:  655 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.840712468193384\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.37395450472831726\n",
            "==========================================\n",
            "Epoch:  656 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.840955284552846\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.19792933762073517\n",
            "==========================================\n",
            "Epoch:  657 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.8401826484018264\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.12497857213020325\n",
            "==========================================\n",
            "Epoch:  658 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.83839918946302\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10176987200975418\n",
            "==========================================\n",
            "Epoch:  659 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8386444107233184\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09674223512411118\n",
            "==========================================\n",
            "Epoch:  660 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.837373737373738\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1936432272195816\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  661 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8376197680282407\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03617735579609871\n",
            "==========================================\n",
            "Epoch:  662 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.840886203423968\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.8198689222335815\n",
            "==========================================\n",
            "Epoch:  663 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 19.0\n",
            "Mean Reward of that batch 6.333333333333333\n",
            "Average Reward of all training: 3.8446455505279036\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.11322394758462906\n",
            "==========================================\n",
            "Epoch:  664 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.8428714859437756\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.05340494588017464\n",
            "==========================================\n",
            "Epoch:  665 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.847619047619048\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.14362144470214844\n",
            "==========================================\n",
            "Epoch:  666 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.851601601601602\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.010515406727790833\n",
            "==========================================\n",
            "Epoch:  667 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.8548225887056478\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.195997953414917\n",
            "==========================================\n",
            "Epoch:  668 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.853542914171657\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.016797544434666634\n",
            "==========================================\n",
            "Epoch:  669 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.8527653213751867\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.24916502833366394\n",
            "==========================================\n",
            "Epoch:  670 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8529850746268655\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.3445640802383423\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  671 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.8537009438648786\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.18153968453407288\n",
            "==========================================\n",
            "Epoch:  672 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.856894841269841\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.6969508528709412\n",
            "==========================================\n",
            "Epoch:  673 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.859336305101535\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09847745299339294\n",
            "==========================================\n",
            "Epoch:  674 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.860286844708209\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.11471892148256302\n",
            "==========================================\n",
            "Epoch:  675 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.864197530864197\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.22403153777122498\n",
            "==========================================\n",
            "Epoch:  676 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.8624260355029585\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.33700650930404663\n",
            "==========================================\n",
            "Epoch:  677 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.863613983259478\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.13040171563625336\n",
            "==========================================\n",
            "Epoch:  678 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.866764995083579\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.20935265719890594\n",
            "==========================================\n",
            "Epoch:  679 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.867697594501718\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.12233300507068634\n",
            "==========================================\n",
            "Epoch:  680 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.867401960784313\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.15189936757087708\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  681 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.872001957905041\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.012344219721853733\n",
            "==========================================\n",
            "Epoch:  682 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.870723362658846\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.48650649189949036\n",
            "==========================================\n",
            "Epoch:  683 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.8689604685212298\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2788812816143036\n",
            "==========================================\n",
            "Epoch:  684 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.871345029239766\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.26444756984710693\n",
            "==========================================\n",
            "Epoch:  685 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.872992700729927\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1327914297580719\n",
            "==========================================\n",
            "Epoch:  686 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.876093294460641\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.27033567428588867\n",
            "==========================================\n",
            "Epoch:  687 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.877244056283357\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0613403283059597\n",
            "==========================================\n",
            "Epoch:  688 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8788759689922485\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.025827405974268913\n",
            "==========================================\n",
            "Epoch:  689 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.8795355587808418\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.14066767692565918\n",
            "==========================================\n",
            "Epoch:  690 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.881642512077294\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.11767720431089401\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  691 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.8847081524360827\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.020355163142085075\n",
            "==========================================\n",
            "Epoch:  692 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.887042389210019\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.26724228262901306\n",
            "==========================================\n",
            "Epoch:  693 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.886243386243386\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.038982030004262924\n",
            "==========================================\n",
            "Epoch:  694 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.886887608069164\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.13179586827754974\n",
            "==========================================\n",
            "Epoch:  695 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8884892086330933\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04796125367283821\n",
            "==========================================\n",
            "Epoch:  696 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8900862068965516\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.08133514970541\n",
            "==========================================\n",
            "Epoch:  697 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.8923959827833574\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -1.2100660800933838\n",
            "==========================================\n",
            "Epoch:  698 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.8925501432664755\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.03435327857732773\n",
            "==========================================\n",
            "Epoch:  699 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.8941344778254647\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.006406852044165134\n",
            "==========================================\n",
            "Epoch:  700 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.8964285714285714\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08571388572454453\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  701 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.898716119828816\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.20696647465229034\n",
            "==========================================\n",
            "Epoch:  702 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.8974358974358974\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.09869012981653214\n",
            "==========================================\n",
            "Epoch:  703 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.89805595068753\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.3707659840583801\n",
            "==========================================\n",
            "Epoch:  704 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.897727272727273\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22439022362232208\n",
            "==========================================\n",
            "Epoch:  705 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.898345153664302\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08676130324602127\n",
            "==========================================\n",
            "Epoch:  706 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.898489140698772\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.12041305005550385\n",
            "==========================================\n",
            "Epoch:  707 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.898632720414898\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.1814803034067154\n",
            "==========================================\n",
            "Epoch:  708 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.9030131826741994\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.12620560824871063\n",
            "==========================================\n",
            "Epoch:  709 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.9022096850023513\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.46861666440963745\n",
            "==========================================\n",
            "Epoch:  710 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.9032863849765254\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.19351176917552948\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  711 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.9069385841537736\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.3672455847263336\n",
            "==========================================\n",
            "Epoch:  712 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 8.5\n",
            "Average Reward of all training: 3.913389513108614\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.15497153997421265\n",
            "==========================================\n",
            "Epoch:  713 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.9153810191678358\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.29559555649757385\n",
            "==========================================\n",
            "Epoch:  714 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.916199813258637\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.010987583547830582\n",
            "==========================================\n",
            "Epoch:  715 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.920512820512821\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.2250005155801773\n",
            "==========================================\n",
            "Epoch:  716 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.9210893854748603\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.12636925280094147\n",
            "==========================================\n",
            "Epoch:  717 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.922594142259414\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.1698569506406784\n",
            "==========================================\n",
            "Epoch:  718 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.9217734447539456\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.10374471545219421\n",
            "==========================================\n",
            "Epoch:  719 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.922345850718591\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2029307782649994\n",
            "==========================================\n",
            "Epoch:  720 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.9231481481481487\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.4462200701236725\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  721 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.924641701340731\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.006027822848409414\n",
            "==========================================\n",
            "Epoch:  722 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.9256694367497693\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22782211005687714\n",
            "==========================================\n",
            "Epoch:  723 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 3.931304748732135\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.19434526562690735\n",
            "==========================================\n",
            "Epoch:  724 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.935543278084715\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.13065816462039948\n",
            "==========================================\n",
            "Epoch:  725 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.934712643678161\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -1.110581398010254\n",
            "==========================================\n",
            "Epoch:  726 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.937557392102847\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.28879234194755554\n",
            "==========================================\n",
            "Epoch:  727 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.9403943145346174\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.0598936527967453\n",
            "==========================================\n",
            "Epoch:  728 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.9391025641025643\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2510767877101898\n",
            "==========================================\n",
            "Epoch:  729 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.9387288523090995\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.06288405507802963\n",
            "==========================================\n",
            "Epoch:  730 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.9383561643835616\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.5303643941879272\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  731 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.937528499772002\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.20614279806613922\n",
            "==========================================\n",
            "Epoch:  732 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.938979963570128\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.42966607213020325\n",
            "==========================================\n",
            "Epoch:  733 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.9404274670304686\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.41273707151412964\n",
            "==========================================\n",
            "Epoch:  734 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.940508628519528\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.044562503695487976\n",
            "==========================================\n",
            "Epoch:  735 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.9426303854875284\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.5668509602546692\n",
            "==========================================\n",
            "Epoch:  736 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.945425724637681\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.014693845994770527\n",
            "==========================================\n",
            "Epoch:  737 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.945499773857983\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.13137903809547424\n",
            "==========================================\n",
            "Epoch:  738 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.9469286359530265\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.18782469630241394\n",
            "==========================================\n",
            "Epoch:  739 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 3.9517365809652687\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.14573165774345398\n",
            "==========================================\n",
            "Epoch:  740 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.9538288288288292\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.17291390895843506\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  741 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.951641925326136\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.4522433578968048\n",
            "==========================================\n",
            "Epoch:  742 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.953054806828392\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.08225099742412567\n",
            "==========================================\n",
            "Epoch:  743 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 3.9558097801704806\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.19808189570903778\n",
            "==========================================\n",
            "Epoch:  744 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.957213261648746\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04070712998509407\n",
            "==========================================\n",
            "Epoch:  745 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.9581655480984343\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.6115775108337402\n",
            "==========================================\n",
            "Epoch:  746 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.9602323503127796\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.7775791883468628\n",
            "==========================================\n",
            "Epoch:  747 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 3.9649709950914773\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.10846272855997086\n",
            "==========================================\n",
            "Epoch:  748 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 7.0\n",
            "Mean Reward of that batch 2.3333333333333335\n",
            "Average Reward of all training: 3.9627896613190736\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07804210484027863\n",
            "==========================================\n",
            "Epoch:  749 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.9619492656875837\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.3873981535434723\n",
            "==========================================\n",
            "Epoch:  750 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.9624444444444444\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22126208245754242\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  751 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.9638260097647584\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.11074215918779373\n",
            "==========================================\n",
            "Epoch:  752 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.964539007092198\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.13879060745239258\n",
            "==========================================\n",
            "Epoch:  753 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 3.963258078795927\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.24541978538036346\n",
            "==========================================\n",
            "Epoch:  754 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.9624226348364275\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.07947548478841782\n",
            "==========================================\n",
            "Epoch:  755 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.962472406181015\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.012775483541190624\n",
            "==========================================\n",
            "Epoch:  756 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.962522045855379\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2578807473182678\n",
            "==========================================\n",
            "Epoch:  757 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.9608102157639804\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.13120362162590027\n",
            "==========================================\n",
            "Epoch:  758 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 3.9599824098504834\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04345667362213135\n",
            "==========================================\n",
            "Epoch:  759 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.963987703118138\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.12756429612636566\n",
            "==========================================\n",
            "Epoch:  760 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 3.9644736842105264\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.22314171493053436\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  761 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 3.966272448532633\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09790142625570297\n",
            "==========================================\n",
            "Epoch:  762 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.967629046369204\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.052068162709474564\n",
            "==========================================\n",
            "Epoch:  763 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 3.9729139362166888\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.18309786915779114\n",
            "==========================================\n",
            "Epoch:  764 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.974912739965096\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.07338940352201462\n",
            "==========================================\n",
            "Epoch:  765 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 8.5\n",
            "Average Reward of all training: 3.98082788671024\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.04662797600030899\n",
            "==========================================\n",
            "Epoch:  766 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.9808529155787644\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09162238985300064\n",
            "==========================================\n",
            "Epoch:  767 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 3.981529769665363\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.09909150749444962\n",
            "==========================================\n",
            "Epoch:  768 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 3.985460069444444\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.9244970679283142\n",
            "==========================================\n",
            "Epoch:  769 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 3.9863459037711313\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2702596187591553\n",
            "==========================================\n",
            "Epoch:  770 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 3.9883116883116885\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.04955562576651573\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  771 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 3.9883268482490273\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.022250723093748093\n",
            "==========================================\n",
            "Epoch:  772 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 3.9866148531951637\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.2878332734107971\n",
            "==========================================\n",
            "Epoch:  773 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 3.989866321690384\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.249025359749794\n",
            "==========================================\n",
            "Epoch:  774 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 3.9950473729543496\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.2759375274181366\n",
            "==========================================\n",
            "Epoch:  775 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 3.996344086021505\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: 0.10857119411230087\n",
            "==========================================\n",
            "Epoch:  776 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 3.995919243986254\n",
            "Max reward for a batch so far: 19.0\n",
            "Training Loss: -0.19506677985191345\n",
            "==========================================\n",
            "Epoch:  777 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 20.0\n",
            "Mean Reward of that batch 6.666666666666667\n",
            "Average Reward of all training: 3.9993564993564994\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.14633749425411224\n",
            "==========================================\n",
            "Epoch:  778 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.002570694087404\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1754089891910553\n",
            "==========================================\n",
            "Epoch:  779 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.00385109114249\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.657765805721283\n",
            "==========================================\n",
            "Epoch:  780 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.0070512820512825\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.14356736838817596\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  781 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.010883482714469\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.11612588912248611\n",
            "==========================================\n",
            "Epoch:  782 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.0115089514066495\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.20742279291152954\n",
            "==========================================\n",
            "Epoch:  783 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.011919965942954\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11194687336683273\n",
            "==========================================\n",
            "Epoch:  784 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.011479591836735\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.23234012722969055\n",
            "==========================================\n",
            "Epoch:  785 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 8.5\n",
            "Average Reward of all training: 4.0171974522293\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.7018524408340454\n",
            "==========================================\n",
            "Epoch:  786 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.019720101781171\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.0799766480922699\n",
            "==========================================\n",
            "Epoch:  787 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.02287166454892\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.2108248770236969\n",
            "==========================================\n",
            "Epoch:  788 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.0232656514382406\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.20306050777435303\n",
            "==========================================\n",
            "Epoch:  789 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.025137304604986\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.4083094894886017\n",
            "==========================================\n",
            "Epoch:  790 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.025738396624472\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.6053018569946289\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  791 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 4.030130636325326\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.12122705578804016\n",
            "==========================================\n",
            "Epoch:  792 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.030513468013468\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.17709441483020782\n",
            "==========================================\n",
            "Epoch:  793 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.030895334174023\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.21475161612033844\n",
            "==========================================\n",
            "Epoch:  794 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.0327455919395465\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.07477958500385284\n",
            "==========================================\n",
            "Epoch:  795 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.034591194968553\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.3117165267467499\n",
            "==========================================\n",
            "Epoch:  796 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.035804020100502\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.020298076793551445\n",
            "==========================================\n",
            "Epoch:  797 / 1000\n",
            "-----------\n",
            "Number of training episodes: 4\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 2.75\n",
            "Average Reward of all training: 4.034190715181932\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.22622939944267273\n",
            "==========================================\n",
            "Epoch:  798 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.037907268170426\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1840912103652954\n",
            "==========================================\n",
            "Epoch:  799 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.0409887359199\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3080969452857971\n",
            "==========================================\n",
            "Epoch:  800 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.0428125\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.160099744796753\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  801 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 4.044839783603829\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.13178931176662445\n",
            "==========================================\n",
            "Epoch:  802 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.0464463840399\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1561732143163681\n",
            "==========================================\n",
            "Epoch:  803 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.047633872976339\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.41486114263534546\n",
            "==========================================\n",
            "Epoch:  804 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.050062189054726\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.020803945139050484\n",
            "==========================================\n",
            "Epoch:  805 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.050414078674948\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.03962010145187378\n",
            "==========================================\n",
            "Epoch:  806 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.050765095119933\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.12320885062217712\n",
            "==========================================\n",
            "Epoch:  807 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.053800082610492\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11686303466558456\n",
            "==========================================\n",
            "Epoch:  808 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.054352310231023\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.09338364005088806\n",
            "==========================================\n",
            "Epoch:  809 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.053049031726411\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.6013551354408264\n",
            "==========================================\n",
            "Epoch:  810 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.055452674897119\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.31955376267433167\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  811 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.056000822030415\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.09191776812076569\n",
            "==========================================\n",
            "Epoch:  812 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.057163382594417\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.019025646150112152\n",
            "==========================================\n",
            "Epoch:  813 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.058323083230832\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.9747745990753174\n",
            "==========================================\n",
            "Epoch:  814 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.0574324324324325\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.048764076083898544\n",
            "==========================================\n",
            "Epoch:  815 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.058588957055215\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.03246231749653816\n",
            "==========================================\n",
            "Epoch:  816 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.060968137254902\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.04752060025930405\n",
            "==========================================\n",
            "Epoch:  817 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.062117503059976\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.10460515320301056\n",
            "==========================================\n",
            "Epoch:  818 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.062449062754687\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.011525403708219528\n",
            "==========================================\n",
            "Epoch:  819 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.061558811558812\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.09904387593269348\n",
            "==========================================\n",
            "Epoch:  820 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.0651422764227645\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4633954167366028\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  821 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.066889971579375\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.02842996083199978\n",
            "==========================================\n",
            "Epoch:  822 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.065997566909975\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2516842782497406\n",
            "==========================================\n",
            "Epoch:  823 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.068955042527339\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.08822662383317947\n",
            "==========================================\n",
            "Epoch:  824 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.0696804207119746\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.18822738528251648\n",
            "==========================================\n",
            "Epoch:  825 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.071414141414142\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.12119194865226746\n",
            "==========================================\n",
            "Epoch:  826 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.072134786117837\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.09514491260051727\n",
            "==========================================\n",
            "Epoch:  827 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.07124143490528\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.7372544407844543\n",
            "==========================================\n",
            "Epoch:  828 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.074778582930757\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.10970161855220795\n",
            "==========================================\n",
            "Epoch:  829 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.075894652191396\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.20623977482318878\n",
            "==========================================\n",
            "Epoch:  830 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.077610441767068\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11837172508239746\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  831 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.081127156036904\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1738436371088028\n",
            "==========================================\n",
            "Epoch:  832 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.082231570512821\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.33603352308273315\n",
            "==========================================\n",
            "Epoch:  833 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.082533013205282\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.0920412540435791\n",
            "==========================================\n",
            "Epoch:  834 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.085431654676259\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2961147427558899\n",
            "==========================================\n",
            "Epoch:  835 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.084530938123753\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.27793020009994507\n",
            "==========================================\n",
            "Epoch:  836 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 4.086423444976076\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.15624172985553741\n",
            "==========================================\n",
            "Epoch:  837 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.086718438868977\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.21488408744335175\n",
            "==========================================\n",
            "Epoch:  838 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.089598249801114\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.05375096574425697\n",
            "==========================================\n",
            "Epoch:  839 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.091279300754867\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.07701237499713898\n",
            "==========================================\n",
            "Epoch:  840 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.090773809523809\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.193052738904953\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  841 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.092251288149029\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11107456684112549\n",
            "==========================================\n",
            "Epoch:  842 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.0937252573238325\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11623538285493851\n",
            "==========================================\n",
            "Epoch:  843 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.096579675761171\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.17204223573207855\n",
            "==========================================\n",
            "Epoch:  844 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.0982424960505535\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.10053423047065735\n",
            "==========================================\n",
            "Epoch:  845 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 4.0965483234714\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.48202332854270935\n",
            "==========================================\n",
            "Epoch:  846 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.096040189125295\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.18442724645137787\n",
            "==========================================\n",
            "Epoch:  847 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.099468713105077\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.229527547955513\n",
            "==========================================\n",
            "Epoch:  848 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.101709905660377\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.7409912347793579\n",
            "==========================================\n",
            "Epoch:  849 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.103160581075775\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1061597689986229\n",
            "==========================================\n",
            "Epoch:  850 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.104803921568627\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.03896370157599449\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  851 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.103505679592636\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.27307090163230896\n",
            "==========================================\n",
            "Epoch:  852 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.104557902973395\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.09859231114387512\n",
            "==========================================\n",
            "Epoch:  853 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.105607659241891\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.17177744209766388\n",
            "==========================================\n",
            "Epoch:  854 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.105874316939891\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.6588580012321472\n",
            "==========================================\n",
            "Epoch:  855 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.10925925925926\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.46641868352890015\n",
            "==========================================\n",
            "Epoch:  856 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.111468068535826\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.14301936328411102\n",
            "==========================================\n",
            "Epoch:  857 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.1136717230649555\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.246506690979004\n",
            "==========================================\n",
            "Epoch:  858 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.113539238539239\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.1450178325176239\n",
            "==========================================\n",
            "Epoch:  859 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.114571206829647\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6191128492355347\n",
            "==========================================\n",
            "Epoch:  860 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.116182170542636\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.30244433879852295\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  861 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.11527293844367\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.0577741861343384\n",
            "==========================================\n",
            "Epoch:  862 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.118619489559165\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.2312566041946411\n",
            "==========================================\n",
            "Epoch:  863 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.120220162224797\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.26006871461868286\n",
            "==========================================\n",
            "Epoch:  864 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.120466820987655\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4206555485725403\n",
            "==========================================\n",
            "Epoch:  865 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.119942196531792\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.037816982716321945\n",
            "==========================================\n",
            "Epoch:  866 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.121343341031563\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.09996064752340317\n",
            "==========================================\n",
            "Epoch:  867 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.122356785851596\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.00042432310874573886\n",
            "==========================================\n",
            "Epoch:  868 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.1237519201228885\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.8351997137069702\n",
            "==========================================\n",
            "Epoch:  869 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.126486382815497\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.10824951529502869\n",
            "==========================================\n",
            "Epoch:  870 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.129214559386973\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.08623169362545013\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  871 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.129831611174896\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.0731402263045311\n",
            "==========================================\n",
            "Epoch:  872 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.131402905198778\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.15311302244663239\n",
            "==========================================\n",
            "Epoch:  873 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.132397861779306\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.33076173067092896\n",
            "==========================================\n",
            "Epoch:  874 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.132246376811595\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.32177498936653137\n",
            "==========================================\n",
            "Epoch:  875 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 4.1298095238095245\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.45653221011161804\n",
            "==========================================\n",
            "Epoch:  876 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.129280821917808\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.1900157928466797\n",
            "==========================================\n",
            "Epoch:  877 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.129703534777651\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.7316024899482727\n",
            "==========================================\n",
            "Epoch:  878 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.132972665148063\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.41244491934776306\n",
            "==========================================\n",
            "Epoch:  879 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.1350967007963595\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.30856117606163025\n",
            "==========================================\n",
            "Epoch:  880 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.133806818181819\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.011924806982278824\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  881 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.133276579644344\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.9064280390739441\n",
            "==========================================\n",
            "Epoch:  882 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.134826152683296\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.46216997504234314\n",
            "==========================================\n",
            "Epoch:  883 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.13637221593054\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.560478687286377\n",
            "==========================================\n",
            "Epoch:  884 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.135463800904978\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.4719539880752563\n",
            "==========================================\n",
            "Epoch:  885 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.137570621468927\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.9274770021438599\n",
            "==========================================\n",
            "Epoch:  886 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.138544018058691\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.12891235947608948\n",
            "==========================================\n",
            "Epoch:  887 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.140642615558061\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3576168119907379\n",
            "==========================================\n",
            "Epoch:  888 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.14329954954955\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.894651472568512\n",
            "==========================================\n",
            "Epoch:  889 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.146512935883015\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.21992334723472595\n",
            "==========================================\n",
            "Epoch:  890 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.148033707865169\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.18536648154258728\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  891 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.1489898989899\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4372830390930176\n",
            "==========================================\n",
            "Epoch:  892 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 4.1533071748878925\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.091245636343956\n",
            "==========================================\n",
            "Epoch:  893 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.154628592758492\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1543346792459488\n",
            "==========================================\n",
            "Epoch:  894 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.156692766592095\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -3.298269033432007\n",
            "==========================================\n",
            "Epoch:  895 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.158193668528864\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3598940968513489\n",
            "==========================================\n",
            "Epoch:  896 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.159691220238096\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.4001230299472809\n",
            "==========================================\n",
            "Epoch:  897 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.159513192121888\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2592419683933258\n",
            "==========================================\n",
            "Epoch:  898 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.160077951002227\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2717342972755432\n",
            "==========================================\n",
            "Epoch:  899 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.161568409343715\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.14432819187641144\n",
            "==========================================\n",
            "Epoch:  900 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.1625\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4338131844997406\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  901 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.161949685534591\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.8945768475532532\n",
            "==========================================\n",
            "Epoch:  902 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.164541759053954\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3834433853626251\n",
            "==========================================\n",
            "Epoch:  903 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.166020671834625\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.695138454437256\n",
            "==========================================\n",
            "Epoch:  904 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.168049410029499\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.27735814452171326\n",
            "==========================================\n",
            "Epoch:  905 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 4.169705340699816\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.38726794719696045\n",
            "==========================================\n",
            "Epoch:  906 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 4.173381162619574\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11088263988494873\n",
            "==========================================\n",
            "Epoch:  907 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 4.17098493201029\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2759811580181122\n",
            "==========================================\n",
            "Epoch:  908 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.170429515418502\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.17270992696285248\n",
            "==========================================\n",
            "Epoch:  909 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.1702420242024205\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6132627725601196\n",
            "==========================================\n",
            "Epoch:  910 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.170787545787546\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4382554292678833\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  911 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.171148920600073\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.22405099868774414\n",
            "==========================================\n",
            "Epoch:  912 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.173154239766082\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4100190997123718\n",
            "==========================================\n",
            "Epoch:  913 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.176250456370938\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.2641597390174866\n",
            "==========================================\n",
            "Epoch:  914 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.176787016776076\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.15109305083751678\n",
            "==========================================\n",
            "Epoch:  915 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.17695810564663\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.23798710107803345\n",
            "==========================================\n",
            "Epoch:  916 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.178948326055313\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2554721534252167\n",
            "==========================================\n",
            "Epoch:  917 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 4.180570701563068\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.48941513895988464\n",
            "==========================================\n",
            "Epoch:  918 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.182552650689906\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.058097194880247116\n",
            "==========================================\n",
            "Epoch:  919 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.183079434167573\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.7623424530029297\n",
            "==========================================\n",
            "Epoch:  920 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.183967391304348\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.5917676091194153\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  921 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.186482084690554\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3264107406139374\n",
            "==========================================\n",
            "Epoch:  922 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.187906724511931\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.36426877975463867\n",
            "==========================================\n",
            "Epoch:  923 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 5.333333333333333\n",
            "Average Reward of all training: 4.1891477067533405\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4936506450176239\n",
            "==========================================\n",
            "Epoch:  924 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.191648629148629\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6552607417106628\n",
            "==========================================\n",
            "Epoch:  925 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.191441441441442\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.24314308166503906\n",
            "==========================================\n",
            "Epoch:  926 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.193394528437725\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.15873263776302338\n",
            "==========================================\n",
            "Epoch:  927 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.193905070118663\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3708440661430359\n",
            "==========================================\n",
            "Epoch:  928 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.194055316091954\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.18974818289279938\n",
            "==========================================\n",
            "Epoch:  929 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.194205238607823\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.8889456391334534\n",
            "==========================================\n",
            "Epoch:  930 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.1950716845878135\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3183065354824066\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  931 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 2.6666666666666665\n",
            "Average Reward of all training: 4.193430003580379\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.74643474817276\n",
            "==========================================\n",
            "Epoch:  932 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.192149499284692\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2612561583518982\n",
            "==========================================\n",
            "Epoch:  933 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.19301536262951\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.10910915583372116\n",
            "==========================================\n",
            "Epoch:  934 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.19387937187723\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.21531327068805695\n",
            "==========================================\n",
            "Epoch:  935 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.194741532976827\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.0443173423409462\n",
            "==========================================\n",
            "Epoch:  936 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 16.0\n",
            "Mean Reward of that batch 8.0\n",
            "Average Reward of all training: 4.19880698005698\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.19127348065376282\n",
            "==========================================\n",
            "Epoch:  937 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.200195659907506\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.11275079101324081\n",
            "==========================================\n",
            "Epoch:  938 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.198916133617626\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.6601107120513916\n",
            "==========================================\n",
            "Epoch:  939 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.200834220802272\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.16131220757961273\n",
            "==========================================\n",
            "Epoch:  940 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.202216312056737\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.2125120609998703\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  941 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.20093871767623\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.175428867340088\n",
            "==========================================\n",
            "Epoch:  942 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.200371549893843\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.18536080420017242\n",
            "==========================================\n",
            "Epoch:  943 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.199098621420997\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.2930630147457123\n",
            "==========================================\n",
            "Epoch:  944 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 6.0\n",
            "Mean Reward of that batch 2.0\n",
            "Average Reward of all training: 4.19676906779661\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.735950469970703\n",
            "==========================================\n",
            "Epoch:  945 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.197619047619047\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.7941358685493469\n",
            "==========================================\n",
            "Epoch:  946 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.200052854122621\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.10005373507738113\n",
            "==========================================\n",
            "Epoch:  947 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.200897571277719\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.802398145198822\n",
            "==========================================\n",
            "Epoch:  948 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.203322784810126\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.3801634609699249\n",
            "==========================================\n",
            "Epoch:  949 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.203811029153495\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.14528301358222961\n",
            "==========================================\n",
            "Epoch:  950 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.20359649122807\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.4488520622253418\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  951 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.203031896249561\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6400824785232544\n",
            "==========================================\n",
            "Epoch:  952 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.2038690476190474\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.5464122295379639\n",
            "==========================================\n",
            "Epoch:  953 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.202955578873731\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.698747158050537\n",
            "==========================================\n",
            "Epoch:  954 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 4.204489867225716\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.5671528577804565\n",
            "==========================================\n",
            "Epoch:  955 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.203228621291448\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.0005983114242554\n",
            "==========================================\n",
            "Epoch:  956 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.201970013947001\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.3481525182724\n",
            "==========================================\n",
            "Epoch:  957 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.202803901079763\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.129762649536133\n",
            "==========================================\n",
            "Epoch:  958 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 18.0\n",
            "Mean Reward of that batch 9.0\n",
            "Average Reward of all training: 4.207811412665275\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.2571757435798645\n",
            "==========================================\n",
            "Epoch:  959 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 4.2112443517553\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.1661333590745926\n",
            "==========================================\n",
            "Epoch:  960 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 8.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.211024305555555\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.06786175072193146\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  961 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.211151578217135\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.46477022767066956\n",
            "==========================================\n",
            "Epoch:  962 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 18.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.213011088011088\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.41397762298583984\n",
            "==========================================\n",
            "Epoch:  963 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.2133091034960195\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6168828010559082\n",
            "==========================================\n",
            "Epoch:  964 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.213433609958506\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.23454229533672333\n",
            "==========================================\n",
            "Epoch:  965 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.214248704663213\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.1797187626361847\n",
            "==========================================\n",
            "Epoch:  966 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.2147170462387855\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.3634689152240753\n",
            "==========================================\n",
            "Epoch:  967 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.214839710444674\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.0189322233200073\n",
            "==========================================\n",
            "Epoch:  968 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 4.21823347107438\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.5470139384269714\n",
            "==========================================\n",
            "Epoch:  969 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.218524251805985\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.4142572581768036\n",
            "==========================================\n",
            "Epoch:  970 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.2208762886597935\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.053697109222412\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  971 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 7.0\n",
            "Average Reward of all training: 4.2237384140061796\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.4126373827457428\n",
            "==========================================\n",
            "Epoch:  972 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 3.0\n",
            "Average Reward of all training: 4.222479423868313\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.5044026374816895\n",
            "==========================================\n",
            "Epoch:  973 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.22156560465913\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.831883192062378\n",
            "==========================================\n",
            "Epoch:  974 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.2216803559206015\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.22448953986167908\n",
            "==========================================\n",
            "Epoch:  975 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.221794871794872\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.2980569303035736\n",
            "==========================================\n",
            "Epoch:  976 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.223104508196721\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.37235525250434875\n",
            "==========================================\n",
            "Epoch:  977 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.223558512453087\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.8139561414718628\n",
            "==========================================\n",
            "Epoch:  978 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 6.5\n",
            "Average Reward of all training: 4.225886162235855\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4403996765613556\n",
            "==========================================\n",
            "Epoch:  979 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.2266768811712625\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.6045379638671875\n",
            "==========================================\n",
            "Epoch:  980 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 5.0\n",
            "Average Reward of all training: 4.227465986394558\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6680462956428528\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  981 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 4.0\n",
            "Average Reward of all training: 4.227234114848793\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.0204427242279053\n",
            "==========================================\n",
            "Epoch:  982 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.228530210454854\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.5877832174301147\n",
            "==========================================\n",
            "Epoch:  983 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.230332316039335\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.5193774700164795\n",
            "==========================================\n",
            "Epoch:  984 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.230436991869919\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -2.0611164569854736\n",
            "==========================================\n",
            "Epoch:  985 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.23087986463621\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.4878094792366028\n",
            "==========================================\n",
            "Epoch:  986 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 18.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.232674104124408\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.050671011209487915\n",
            "==========================================\n",
            "Epoch:  987 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 17.0\n",
            "Mean Reward of that batch 5.666666666666667\n",
            "Average Reward of all training: 4.234126984126984\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 1.233311414718628\n",
            "==========================================\n",
            "Epoch:  988 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.235914304993252\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 1.4877254962921143\n",
            "==========================================\n",
            "Epoch:  989 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 3.6666666666666665\n",
            "Average Reward of all training: 4.235338725985844\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.8065272569656372\n",
            "==========================================\n",
            "Epoch:  990 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.23577441077441\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.8351404666900635\n",
            "Model saved\n",
            "==========================================\n",
            "Epoch:  991 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 9.0\n",
            "Mean Reward of that batch 4.5\n",
            "Average Reward of all training: 4.236041035990581\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.5452921390533447\n",
            "==========================================\n",
            "Epoch:  992 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 11.0\n",
            "Mean Reward of that batch 5.5\n",
            "Average Reward of all training: 4.237315188172042\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.6032337546348572\n",
            "==========================================\n",
            "Epoch:  993 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.237747566297415\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.037363603711128235\n",
            "==========================================\n",
            "Epoch:  994 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 14.0\n",
            "Mean Reward of that batch 4.666666666666667\n",
            "Average Reward of all training: 4.2381790744466805\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -1.307197093963623\n",
            "==========================================\n",
            "Epoch:  995 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 15.0\n",
            "Mean Reward of that batch 7.5\n",
            "Average Reward of all training: 4.241457286432161\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 1.1208641529083252\n",
            "==========================================\n",
            "Epoch:  996 / 1000\n",
            "-----------\n",
            "Number of training episodes: 2\n",
            "Total reward: 12.0\n",
            "Mean Reward of that batch 6.0\n",
            "Average Reward of all training: 4.243222891566265\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -7.163599014282227\n",
            "==========================================\n",
            "Epoch:  997 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.243313273152792\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.27075013518333435\n",
            "==========================================\n",
            "Epoch:  998 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 13.0\n",
            "Mean Reward of that batch 4.333333333333333\n",
            "Average Reward of all training: 4.243403473613894\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.13395340740680695\n",
            "==========================================\n",
            "Epoch:  999 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.2424924924924925\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: 0.9346827864646912\n",
            "==========================================\n",
            "Epoch:  1000 / 1000\n",
            "-----------\n",
            "Number of training episodes: 3\n",
            "Total reward: 10.0\n",
            "Mean Reward of that batch 3.3333333333333335\n",
            "Average Reward of all training: 4.241583333333333\n",
            "Max reward for a batch so far: 20.0\n",
            "Training Loss: -0.3429364562034607\n",
            "Model saved\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtjUlwGsNTJc",
        "colab_type": "text"
      },
      "source": [
        "### 9. Agent play\n",
        "\n",
        "Now that we trained our agent, we can test i\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "azCYJ68INHEL",
        "colab_type": "code",
        "outputId": "0f69d2ab-e711-463f-bf50-a23e36de7297",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        }
      },
      "source": [
        "# Saver\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "with tf.Session() as sess:\n",
        "    game = DoomGame()\n",
        "\n",
        "    # Load the correct configuration \n",
        "    game.load_config(\"defend_the_center.cfg\")\n",
        "    \n",
        "    # Load the correct scenario (in our case basic scenario)\n",
        "    game.set_doom_scenario_path(\"defend_the_center.wad\")\n",
        "    \n",
        "    # Load the model\n",
        "    saver.restore(sess, \"./models/model.ckpt\")\n",
        "    game.set_window_visible(False)\n",
        "    game.init()\n",
        "    \n",
        "    for i in range(10):\n",
        "        \n",
        "        # Launch a new episode\n",
        "        game.new_episode()\n",
        "\n",
        "        # Get a new state\n",
        "        state = game.get_state().screen_buffer\n",
        "        state, stacked_frames = stack_frames(stacked_frames, state, True)\n",
        "\n",
        "        while not game.is_episode_finished():\n",
        "        \n",
        "            # Run State Through Policy & Calculate Action\n",
        "            action_probability_distribution = sess.run(PGNetwork.action_distribution, \n",
        "                                                       feed_dict={PGNetwork.inputs_: state.reshape(1, *state_size)})\n",
        "\n",
        "            # REMEMBER THAT WE ARE IN A STOCHASTIC POLICY SO WE DON'T ALWAYS TAKE THE ACTION WITH THE HIGHEST PROBABILITY\n",
        "            # (For instance if the action with the best probability for state S is a1 with 70% chances, there is\n",
        "            #30% chance that we take action a2)\n",
        "            action = np.random.choice(range(action_probability_distribution.shape[1]), \n",
        "                                      p=action_probability_distribution.ravel())  # select action w.r.t the actions prob\n",
        "            action = possible_actions[action]\n",
        "\n",
        "            # Perform action\n",
        "            reward = game.make_action(action)\n",
        "            done = game.is_episode_finished()\n",
        "            \n",
        "            if done:\n",
        "                break\n",
        "            else:\n",
        "                # If not done, the next_state become the current state\n",
        "                next_state = game.get_state().screen_buffer\n",
        "                next_state, stacked_frames = stack_frames(stacked_frames, next_state, False)\n",
        "                state = next_state\n",
        "        \n",
        "\n",
        "        print(\"Score for episode \", i, \" :\", game.get_total_reward())\n",
        "    game.close()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from ./models/model.ckpt\n",
            "Score for episode  0  : 3.0\n",
            "Score for episode  1  : 1.0\n",
            "Score for episode  2  : 5.0\n",
            "Score for episode  3  : 1.0\n",
            "Score for episode  4  : 3.0\n",
            "Score for episode  5  : 4.0\n",
            "Score for episode  6  : 6.0\n",
            "Score for episode  7  : 9.0\n",
            "Score for episode  8  : 7.0\n",
            "Score for episode  9  : 3.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}