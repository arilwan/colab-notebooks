{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.2"
    },
    "colab": {
      "name": "01-neural-processes-pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/neural-processes/02-neural-processes-keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFt47sOZ49B4",
        "colab_type": "code",
        "outputId": "4da17c5e-416b-4aa6-cf23-7f25a051e149",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Sep 30 05:13:17 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjZsFXR8BWfM",
        "colab_type": "code",
        "outputId": "91683184-ff6d-4070-d47d-e9aae8147229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        }
      },
      "source": [
        "!git clone https://github.com/martin-fabbri/colab-notebooks"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'colab-notebooks'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (175/175), done.\u001b[K\n",
            "remote: Total 356 (delta 112), reused 79 (delta 30), pack-reused 147\u001b[K\n",
            "Receiving objects: 100% (356/356), 9.63 MiB | 24.29 MiB/s, done.\n",
            "Resolving deltas: 100% (190/190), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Hi0gIkKBbH4",
        "colab_type": "code",
        "outputId": "cfcfa1e5-6b66-47f5-eb6c-84a5e6152ca7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "tfe = tf.contrib.eager\n",
        "tf.enable_eager_execution()\n",
        "\n",
        "print('tf:', tf.__version__)\n",
        "print('tfp:', tfp.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tf: 1.14.0\n",
            "tfp: 0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vgErR1IYbXi0",
        "colab_type": "text"
      },
      "source": [
        "### Define TensorFlow probability distribution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_PEbovkcbpbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Normal = tfp.distributions.Normal\n",
        "KL = tfp.distributions.kl_divergence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x0ksBxD5cBx3",
        "colab_type": "text"
      },
      "source": [
        "### Define neural nets for inference and generating over data input and latent samples"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MdR_Tdk_bEYn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NP(tf.keras.Model):\n",
        "    def __init__(self, r_in_dim, l1_dim, r_out_dim, z_dim, de_out):\n",
        "        super(NP, self).__init__()\n",
        "        \n",
        "        # input dimensions to represenation encoder\n",
        "        self.r_in_dim = r_in_dim\n",
        "        \n",
        "        # representation encoder and generative net hidden dimension \n",
        "        self.l1_dim = l1_dim\n",
        "        \n",
        "        # representation encoder output dimension\n",
        "        self.r_out_dim = r_out_dim\n",
        "        \n",
        "        # latent dimension\n",
        "        self.z_dim = z_dim\n",
        "        \n",
        "        # decoder output dimension\n",
        "        self.de_out = de_out\n",
        "        \n",
        "        # representation encoder\n",
        "        self.r_encoder = tf.keras.Sequential(\n",
        "          [\n",
        "          tf.keras.layers.InputLayer(input_shape=(self.r_in_dim,)),\n",
        "          tf.keras.layers.Dense(self.l1_dim, activation=tf.nn.elu),\n",
        "          tf.keras.layers.Dense(self.r_out_dim)])\n",
        "        \n",
        "        # inference model to estimate the posterior\n",
        "        self.inference_net = tf.keras.Sequential(\n",
        "          [\n",
        "          tf.keras.layers.InputLayer(input_shape=(self.r_out_dim,)),\n",
        "          tf.keras.layers.Dense(self.z_dim + self.z_dim)])\n",
        "        \n",
        "        # generative model to estimate the likelihood p(x|z) for latent samples\n",
        "        self.generative_net = tf.keras.Sequential(\n",
        "          [\n",
        "          tf.keras.layers.InputLayer(input_shape=(self.z_dim, self.z_dim + self.de_out,)),\n",
        "          tf.keras.layers.Dense(self.l1_dim, activation=tf.nn.sigmoid),\n",
        "          tf.keras.layers.Dense(self.de_out)])\n",
        "    \n",
        "    # function encoding and inference to estimate the posterior in latent space z     \n",
        "    def zencode(self, x,y):\n",
        "        xy = tf.concat([x,y], axis=1)\n",
        "        r = self.r_encoder(xy)\n",
        "        r_agg = tf.reshape(tf.reduce_mean(r, axis=0),[1,-1])\n",
        "        mean, logvar = tf.split(self.inference_net(r_agg), num_or_size_splits=2, axis=1)\n",
        "        return mean, tf.nn.softplus(logvar)\n",
        "\n",
        "    # generation of latent samples from the posterior estimate (30 samples)\n",
        "    def reparameterize(self, mean, sigma, n=10):\n",
        "        # generate latent sample using Gaussian reparamaterization\n",
        "        z = mean + sigma * tf.random_normal(shape=(n, self.z_dim))\n",
        "        return z\n",
        "    \n",
        "    # generate function samples of y_test using x_test and latent samples\n",
        "    def decode(self, x_star, z, noise_sd = 0.05):\n",
        "        N_star = tf.shape(x_star)[0]\n",
        "        n_draws = z.get_shape().as_list()[0]\n",
        "        x_star_sample = tf.tile(tf.expand_dims(x_star, [0]),(n_draws,1,1))\n",
        "        z_sample = tf.tile(tf.expand_dims(z, [1]),(1,N_star,1))\n",
        "        xz = [x_star_sample, z_sample]\n",
        "        xz_concat = tf.concat(xz, axis=2)\n",
        "        mean_x_star = tf.transpose(tf.squeeze(self.generative_net(xz_concat), axis=2))\n",
        "        return mean_x_star, tf.constant(noise_sd)\n",
        "    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oczbw_krsif",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# define neural process loss function \n",
        "def np_loss(model, x_all, y_all, x_c, y_c, x_t, y_t):\n",
        "    z_mean_all, z_std_all = model.zencode(x_all, y_all)\n",
        "    z_mean_context, z_std_context = model.zencode(x_c, y_c)\n",
        "    z = model.reparameterize(z_mean_all, z_std_all)\n",
        "    mu, std = model.decode(x_t, z)\n",
        "    reconstruction_error = tf.reduce_sum(Normal(loc=mu, scale=std).log_prob(y_t),axis=0)\n",
        "    q_z = Normal(loc=z_mean_all, scale=z_std_all)\n",
        "    p_z = Normal(loc=z_mean_context, scale=z_std_context)\n",
        "    KL_qp = KL(q_z, p_z)\n",
        "    KL_qp_sum = tf.reduce_sum(KL_qp)\n",
        "    ELBO = tf.reduce_mean(reconstruction_error - KL_qp_sum)\n",
        "    loss = -ELBO\n",
        "    return loss\n",
        "\n",
        "# compute gradients and loss using Tensorflow Eager execution\n",
        "def compute_gradients(model, x_all, y_all, x_c, y_c, x_t, y_t):\n",
        "    with tf.GradientTape() as tape:\n",
        "        loss = np_loss(model, x_all, y_all, x_c, y_c, x_t, y_t)\n",
        "    return tape.gradient(loss, model.trainable_variables), loss\n",
        "\n",
        "def apply_gradients(optimizer, gradients, variables, global_step=None):\n",
        "    return optimizer.apply_gradients(zip(gradients, variables), global_step=global_step)\n",
        "\n",
        "# randomly split input series into x,y context and x,y test sets\n",
        "def random_split_context_target(x,y, n_context):\n",
        "    ind = np.arange(x.shape[0])\n",
        "    mask = np.random.choice(ind, size=n_context, replace=False)\n",
        "    return x[mask], y[mask], np.delete(x, mask, axis=0), np.delete(y, mask, axis=0)\n",
        "\n",
        "# plot function samples for unseen x inputs\n",
        "def visualise(model, x, y, x_star, epoch):\n",
        "    plt.figure(figsize=(8,8))\n",
        "    z_mu, z_std = model.zencode(x,y)\n",
        "    zsamples = model.reparameterize(z_mu, z_std, 30)\n",
        "    mu, _ = model.decode(x_star, zsamples)\n",
        "    for i in range(mu.shape[1]):\n",
        "        plt.plot(x_star.numpy(), mu.numpy()[:,i], linewidth=1)\n",
        "    \n",
        "    plt.scatter(x.numpy(), y.numpy())\n",
        "    plt.title('Function Samples for New Input at Epoch {}'.format(epoch))\n",
        "    plt.xlabel('x')\n",
        "    plt.ylabel('y')\n",
        "    plt.savefig('posterior_{}.png'.format(epoch), bbox_inches='tight')\n",
        "    plt.clf()\n",
        "    plt.cla()\n",
        "    plt.close()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKB_Ygakq9eg",
        "colab_type": "text"
      },
      "source": [
        "### Encode and infere posterior in latent space z"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nuurVdCwrUBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "affc0d53-146d-4954-fec0-e0899581687f"
      },
      "source": [
        "print(\"TensorFlow version: {}\".format(tf.VERSION))\n",
        "print(\"Eager execution: {}\".format(tf.executing_eagerly()))\n",
        "\n",
        "r_in_dim = 2\n",
        "l1_dim = 8\n",
        "r_out_dim = 2\n",
        "z_dim = 2\n",
        "de_out = 1\n",
        "\n",
        "epochs = 10001\n",
        "lr_init = 0.001\n",
        "\n",
        "lr = tfe.Variable(lr_init, name = \"learning_rate\", trainable=False)\n",
        "\n",
        "optimizer = tf.train.AdamOptimizer(lr)\n",
        "\n",
        "model = NP(r_in_dim, l1_dim, r_out_dim, z_dim, de_out)\n",
        "\n",
        "# define input range\n",
        "all_x_np = np.arange(-2,3,1).reshape(-1,1).astype(np.float32)\n",
        "\n",
        "# define output range (tests peformed with noise)\n",
        "all_y_np = np.sin(all_x_np) #+ np.random.normal(size=1).astype(np.float32)\n",
        "\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    x_context, y_context, x_target, y_target = random_split_context_target(\n",
        "                            all_x_np, all_y_np, np.random.randint(1,4))\n",
        "    x_c = tfe.Variable(x_context)\n",
        "    x_t = tfe.Variable(x_target)\n",
        "    y_c = tfe.Variable(y_context)\n",
        "    y_t = tfe.Variable(y_target)\n",
        "\n",
        "    x_all = tf.concat([x_c, x_t], axis=0)\n",
        "    y_all = tf.concat([y_c, y_t], axis=0)\n",
        "\n",
        "    gradients, loss = compute_gradients(model, x_all, y_all, x_c, y_c, x_t, y_t)\n",
        "    apply_gradients(optimizer, gradients, model.trainable_variables)\n",
        "\n",
        "    loss_list.append(loss)\n",
        "\n",
        "    if epoch % 200 == 0:\n",
        "        x_g = tfe.Variable(np.arange(-4,4, 0.1).reshape(-1,1).astype(np.float32))\n",
        "        visualise(model, x_all, y_all, x_g, epoch)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow version: 1.14.0\n",
            "Eager execution: True\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}