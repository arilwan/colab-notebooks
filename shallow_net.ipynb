{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "shallow_net.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "jbW1IaJFS-_s"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martin-fabbri/colab-notebooks/blob/master/shallow_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iXlSZrKWUrKe",
        "colab_type": "text"
      },
      "source": [
        "# Shallow Neural Network in TensorFlow 2.0 (DEMO)\n",
        "\n",
        "A shallow neural network that classifies MNIST digits.\n",
        "\n",
        "_Remember to change your Runtime to GPU or TPU._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbW1IaJFS-_s",
        "colab_type": "text"
      },
      "source": [
        "#### Checking environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYG9DhRYS-Rd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "outputId": "073edf56-30c8-4983-e8d3-77f929e59163"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Sep 18 16:55:04 2019       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 430.40       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8    28W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73o58FcYZ0zM",
        "colab_type": "text"
      },
      "source": [
        "#### Load dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NjWz0tCca3Xq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dENc85VWa7OZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "5fae7b56-e747-4364-8f5b-c470d3fbc49e"
      },
      "source": [
        "!pip freeze | grep tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow==0.0.5\n",
            "tensorflow==1.14.0\n",
            "tensorflow-estimator==1.14.0\n",
            "tensorflow-hub==0.6.0\n",
            "tensorflow-metadata==0.14.0\n",
            "tensorflow-probability==0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ-BfzyGa9K7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "outputId": "af5904d3-52df-4949-e238-7386d02111fa"
      },
      "source": [
        "pip install tensorflow==2.0.0-beta0"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0-beta0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6c/19/0d0c7f240db7bcd6b83783b9a89a67f38584d100e23ad5ae93114be92232/tensorflow-2.0.0b0-cp36-cp36m-manylinux1_x86_64.whl (87.9MB)\n",
            "\u001b[K     |████████████████████████████████| 87.9MB 1.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.2.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (3.7.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.12.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.11.2)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.33.6)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.0.8)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 43.0MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow==2.0.0-beta0)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.8.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.1.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.16.5)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0-beta0) (0.1.7)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0-beta0) (41.2.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow==2.0.0-beta0) (2.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (0.15.6)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow==2.0.0-beta0) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow\n",
            "  Found existing installation: tensorflow 1.14.0\n",
            "    Uninstalling tensorflow-1.14.0:\n",
            "      Successfully uninstalled tensorflow-1.14.0\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-2.0.0b0 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QTF7OhJQbBut",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "56Ye_R4-bo3U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "a69be2e3-73bc-468d-bf23-23d84e9f931b"
      },
      "source": [
        "!pip freeze | grep tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mesh-tensorflow==0.0.5\n",
            "tensorflow==2.0.0b0\n",
            "tensorflow-estimator==1.14.0\n",
            "tensorflow-hub==0.6.0\n",
            "tensorflow-metadata==0.14.0\n",
            "tensorflow-probability==0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MxdWaDnMbrw9",
        "colab_type": "text"
      },
      "source": [
        "#### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wH9kdTH8bxty",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "30f51b47-f23d-459a-ced4-ddf28257ddaf"
      },
      "source": [
        "(X_train, y_train), (X_valid, y_valid) = keras.datasets.mnist.load_data()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ2PPkMKcC1S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ab00c4bd-ab26-4e5f-87ca-20f53ae5d33a"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B_oHXNAgcGn-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3de9fb7e-7e85-4f2c-fc28-83e3c21a0bd7"
      },
      "source": [
        "y_train.shape"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KfHwa61ycLZc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b8ac2930-e5a5-4ae9-ea5d-c967e2a47d23"
      },
      "source": [
        "y_train[0:12]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "btF3_fWOegzU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "0c3ba237-182b-45dd-e443-dd71511c7807"
      },
      "source": [
        "from matplotlib import pyplot as plt\n",
        "plt.figure(figsize=(5,5))\n",
        "for k in range(12):\n",
        "    plt.subplot(3, 4, k+1)\n",
        "    plt.imshow(X_train[k], cmap='Greys')\n",
        "    plt.axis('off')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAE/CAYAAAB8TMlTAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 360x360 with 12 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pFT_CIJbep24",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a182d98f-0909-48fc-f48d-5980c518eaed"
      },
      "source": [
        "X_valid.shape"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, 28, 28)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQi3oC4esYo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7c74f395-6632-4dd0-df89-ef1b4da95fdb"
      },
      "source": [
        "y_valid.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwwJ04ZOettt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "545ee5cf-7031-4580-9c55-77ec19d59593"
      },
      "source": [
        "plt.imshow(X_valid[0], cmap=\"Greys\")"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f33765d2278>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0kRfiApwg8kRfiBpP4Pc0oGVHoLWbQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yKQKR_AIezMg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1fc49ceb-b1e7-4078-ff59-1878b569a87b"
      },
      "source": [
        "X_valid[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  84, 185, 159, 151,  60,  36,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0, 222, 254, 254, 254, 254, 241, 198,\n",
              "        198, 198, 198, 198, 198, 198, 198, 170,  52,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,  67, 114,  72, 114, 163, 227, 254,\n",
              "        225, 254, 254, 254, 250, 229, 254, 254, 140,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  17,  66,\n",
              "         14,  67,  67,  67,  59,  21, 236, 254, 106,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,  83, 253, 209,  18,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,  22, 233, 255,  83,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0, 129, 254, 238,  44,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,  59, 249, 254,  62,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0, 133, 254, 187,   5,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   9, 205, 248,  58,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0, 126, 254, 182,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,  75, 251, 240,  57,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "         19, 221, 254, 166,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
              "        203, 254, 219,  35,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  38,\n",
              "        254, 254,  77,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  31, 224,\n",
              "        254, 115,   1,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 133, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  61, 242, 254,\n",
              "        254,  52,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 254,\n",
              "        219,  40,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 121, 254, 207,\n",
              "         18,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0],\n",
              "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
              "          0,   0]], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RZ6J0L1fe1m4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0b2f9722-cdf3-465a-be17-dd1b6232b59d"
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jyMuVQvibzRu",
        "colab_type": "text"
      },
      "source": [
        "#### Preprocess data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hw0FtUpYb4Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = X_train.reshape(60000, 784).astype('float32')\n",
        "X_valid = X_valid.reshape(10000, 784).astype('float32')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EkyGxyRIb5md",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train /= 255\n",
        "X_valid /= 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxRjPNpNe-Gm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "eb066e75-95f6-47a2-e216-934e08de9e40"
      },
      "source": [
        "X_valid[0]"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.32941177, 0.7254902 , 0.62352943,\n",
              "       0.5921569 , 0.23529412, 0.14117648, 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.87058824, 0.99607843, 0.99607843, 0.99607843, 0.99607843,\n",
              "       0.94509804, 0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 ,\n",
              "       0.7764706 , 0.7764706 , 0.7764706 , 0.7764706 , 0.6666667 ,\n",
              "       0.20392157, 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.2627451 , 0.44705883,\n",
              "       0.28235295, 0.44705883, 0.6392157 , 0.8901961 , 0.99607843,\n",
              "       0.88235295, 0.99607843, 0.99607843, 0.99607843, 0.98039216,\n",
              "       0.8980392 , 0.99607843, 0.99607843, 0.54901963, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.06666667, 0.25882354, 0.05490196, 0.2627451 ,\n",
              "       0.2627451 , 0.2627451 , 0.23137255, 0.08235294, 0.9254902 ,\n",
              "       0.99607843, 0.41568628, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.3254902 , 0.99215686, 0.81960785, 0.07058824,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.08627451, 0.9137255 ,\n",
              "       1.        , 0.3254902 , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.5058824 , 0.99607843, 0.93333334, 0.17254902,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.23137255, 0.9764706 ,\n",
              "       0.99607843, 0.24313726, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.52156866, 0.99607843, 0.73333335, 0.01960784,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.03529412, 0.8039216 ,\n",
              "       0.972549  , 0.22745098, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.49411765, 0.99607843, 0.7137255 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.29411766, 0.9843137 ,\n",
              "       0.9411765 , 0.22352941, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.07450981, 0.8666667 , 0.99607843, 0.6509804 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.01176471, 0.79607844, 0.99607843,\n",
              "       0.85882354, 0.13725491, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.14901961, 0.99607843, 0.99607843, 0.3019608 , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.12156863, 0.8784314 , 0.99607843,\n",
              "       0.4509804 , 0.00392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.52156866, 0.99607843, 0.99607843, 0.20392157, 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.23921569, 0.9490196 , 0.99607843,\n",
              "       0.99607843, 0.20392157, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.4745098 , 0.99607843, 0.99607843, 0.85882354, 0.15686275,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.4745098 , 0.99607843,\n",
              "       0.8117647 , 0.07058824, 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
              "       0.        , 0.        , 0.        , 0.        ], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7rJ2C_ob6e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "n_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, n_classes)\n",
        "y_valid = keras.utils.to_categorical(y_valid, n_classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20zL0e_ZfDxo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "effdefd4-7115-41a7-9939-b3ba09937c3b"
      },
      "source": [
        "y_valid[0]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FrDbdiVqb7eN",
        "colab_type": "text"
      },
      "source": [
        "#### Design neural network architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pTgQAJCFb-Tm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = keras.models.Sequential([\n",
        "    \n",
        "    keras.layers.Dense(64, activation='sigmoid', input_shape=(784,)),\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "    \n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzSU6ALogRJv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "d0f01e11-c005-4a9b-e0b6-832bc5a3db60"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 64)                50240     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 50,890\n",
            "Trainable params: 50,890\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmKYRyaTgTTx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3baac464-12ce-42e6-96a3-4e90611cc6a1"
      },
      "source": [
        "64*784"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50176"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLgX7mIMgXVR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "59331dc6-b0ca-4211-8cab-3972da893e3d"
      },
      "source": [
        "(64*784)+64"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "50240"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ep92qZmsgarR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a5d2e451-7e73-46e1-8341-04b694056723"
      },
      "source": [
        "(10*64)+10"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "650"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-W1ljeaGgdpA",
        "colab_type": "text"
      },
      "source": [
        "#### Configure model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2YI73ZvYgheG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mean_squared_error', optimizer='sgd', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NV9-heXwgqO2",
        "colab_type": "text"
      },
      "source": [
        "#### Train!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WtgS2Xhmgx4X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1bc1eaa5-b833-460a-9a63-28663c8a5098"
      },
      "source": [
        "model.fit(X_train, y_train, batch_size=128, epochs=200, verbose=1, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/200\n",
            "60000/60000 [==============================] - 1s 25us/sample - loss: 0.0921 - accuracy: 0.1020 - val_loss: 0.0913 - val_accuracy: 0.1012\n",
            "Epoch 2/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0909 - accuracy: 0.1030 - val_loss: 0.0905 - val_accuracy: 0.1056\n",
            "Epoch 3/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0903 - accuracy: 0.1146 - val_loss: 0.0900 - val_accuracy: 0.1260\n",
            "Epoch 4/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0898 - accuracy: 0.1356 - val_loss: 0.0896 - val_accuracy: 0.1514\n",
            "Epoch 5/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0895 - accuracy: 0.1639 - val_loss: 0.0893 - val_accuracy: 0.1815\n",
            "Epoch 6/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0891 - accuracy: 0.1975 - val_loss: 0.0889 - val_accuracy: 0.2159\n",
            "Epoch 7/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0888 - accuracy: 0.2315 - val_loss: 0.0886 - val_accuracy: 0.2497\n",
            "Epoch 8/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0885 - accuracy: 0.2629 - val_loss: 0.0883 - val_accuracy: 0.2785\n",
            "Epoch 9/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0882 - accuracy: 0.2918 - val_loss: 0.0880 - val_accuracy: 0.3096\n",
            "Epoch 10/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0879 - accuracy: 0.3223 - val_loss: 0.0877 - val_accuracy: 0.3351\n",
            "Epoch 11/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0876 - accuracy: 0.3505 - val_loss: 0.0874 - val_accuracy: 0.3648\n",
            "Epoch 12/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0873 - accuracy: 0.3801 - val_loss: 0.0871 - val_accuracy: 0.3919\n",
            "Epoch 13/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0870 - accuracy: 0.4116 - val_loss: 0.0868 - val_accuracy: 0.4240\n",
            "Epoch 14/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0867 - accuracy: 0.4376 - val_loss: 0.0865 - val_accuracy: 0.4511\n",
            "Epoch 15/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0864 - accuracy: 0.4579 - val_loss: 0.0862 - val_accuracy: 0.4665\n",
            "Epoch 16/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0861 - accuracy: 0.4691 - val_loss: 0.0859 - val_accuracy: 0.4755\n",
            "Epoch 17/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0858 - accuracy: 0.4749 - val_loss: 0.0855 - val_accuracy: 0.4800\n",
            "Epoch 18/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0855 - accuracy: 0.4767 - val_loss: 0.0852 - val_accuracy: 0.4822\n",
            "Epoch 19/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0851 - accuracy: 0.4757 - val_loss: 0.0848 - val_accuracy: 0.4823\n",
            "Epoch 20/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0848 - accuracy: 0.4757 - val_loss: 0.0845 - val_accuracy: 0.4818\n",
            "Epoch 21/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0844 - accuracy: 0.4738 - val_loss: 0.0841 - val_accuracy: 0.4809\n",
            "Epoch 22/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0840 - accuracy: 0.4725 - val_loss: 0.0837 - val_accuracy: 0.4781\n",
            "Epoch 23/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0837 - accuracy: 0.4707 - val_loss: 0.0833 - val_accuracy: 0.4765\n",
            "Epoch 24/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0833 - accuracy: 0.4683 - val_loss: 0.0829 - val_accuracy: 0.4745\n",
            "Epoch 25/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0829 - accuracy: 0.4666 - val_loss: 0.0825 - val_accuracy: 0.4732\n",
            "Epoch 26/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0825 - accuracy: 0.4653 - val_loss: 0.0821 - val_accuracy: 0.4722\n",
            "Epoch 27/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0820 - accuracy: 0.4633 - val_loss: 0.0817 - val_accuracy: 0.4719\n",
            "Epoch 28/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0816 - accuracy: 0.4644 - val_loss: 0.0812 - val_accuracy: 0.4708\n",
            "Epoch 29/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0812 - accuracy: 0.4632 - val_loss: 0.0808 - val_accuracy: 0.4708\n",
            "Epoch 30/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0807 - accuracy: 0.4639 - val_loss: 0.0803 - val_accuracy: 0.4717\n",
            "Epoch 31/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0803 - accuracy: 0.4647 - val_loss: 0.0799 - val_accuracy: 0.4724\n",
            "Epoch 32/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0798 - accuracy: 0.4654 - val_loss: 0.0794 - val_accuracy: 0.4731\n",
            "Epoch 33/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0794 - accuracy: 0.4669 - val_loss: 0.0789 - val_accuracy: 0.4747\n",
            "Epoch 34/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0789 - accuracy: 0.4686 - val_loss: 0.0785 - val_accuracy: 0.4762\n",
            "Epoch 35/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0784 - accuracy: 0.4698 - val_loss: 0.0780 - val_accuracy: 0.4784\n",
            "Epoch 36/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0779 - accuracy: 0.4725 - val_loss: 0.0775 - val_accuracy: 0.4797\n",
            "Epoch 37/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0774 - accuracy: 0.4739 - val_loss: 0.0770 - val_accuracy: 0.4822\n",
            "Epoch 38/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0769 - accuracy: 0.4765 - val_loss: 0.0765 - val_accuracy: 0.4848\n",
            "Epoch 39/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0764 - accuracy: 0.4792 - val_loss: 0.0760 - val_accuracy: 0.4867\n",
            "Epoch 40/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0759 - accuracy: 0.4813 - val_loss: 0.0755 - val_accuracy: 0.4889\n",
            "Epoch 41/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0754 - accuracy: 0.4842 - val_loss: 0.0749 - val_accuracy: 0.4910\n",
            "Epoch 42/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0749 - accuracy: 0.4868 - val_loss: 0.0744 - val_accuracy: 0.4935\n",
            "Epoch 43/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0744 - accuracy: 0.4895 - val_loss: 0.0739 - val_accuracy: 0.4965\n",
            "Epoch 44/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0739 - accuracy: 0.4922 - val_loss: 0.0734 - val_accuracy: 0.4987\n",
            "Epoch 45/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0734 - accuracy: 0.4949 - val_loss: 0.0729 - val_accuracy: 0.5015\n",
            "Epoch 46/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0729 - accuracy: 0.4983 - val_loss: 0.0724 - val_accuracy: 0.5055\n",
            "Epoch 47/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0724 - accuracy: 0.5013 - val_loss: 0.0718 - val_accuracy: 0.5081\n",
            "Epoch 48/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0719 - accuracy: 0.5044 - val_loss: 0.0713 - val_accuracy: 0.5109\n",
            "Epoch 49/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0713 - accuracy: 0.5073 - val_loss: 0.0708 - val_accuracy: 0.5142\n",
            "Epoch 50/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0708 - accuracy: 0.5112 - val_loss: 0.0703 - val_accuracy: 0.5177\n",
            "Epoch 51/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0703 - accuracy: 0.5146 - val_loss: 0.0698 - val_accuracy: 0.5212\n",
            "Epoch 52/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0698 - accuracy: 0.5179 - val_loss: 0.0692 - val_accuracy: 0.5254\n",
            "Epoch 53/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0693 - accuracy: 0.5212 - val_loss: 0.0687 - val_accuracy: 0.5287\n",
            "Epoch 54/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0688 - accuracy: 0.5243 - val_loss: 0.0682 - val_accuracy: 0.5330\n",
            "Epoch 55/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0683 - accuracy: 0.5285 - val_loss: 0.0677 - val_accuracy: 0.5375\n",
            "Epoch 56/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0678 - accuracy: 0.5328 - val_loss: 0.0672 - val_accuracy: 0.5417\n",
            "Epoch 57/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0673 - accuracy: 0.5368 - val_loss: 0.0667 - val_accuracy: 0.5456\n",
            "Epoch 58/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0668 - accuracy: 0.5406 - val_loss: 0.0662 - val_accuracy: 0.5491\n",
            "Epoch 59/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0663 - accuracy: 0.5441 - val_loss: 0.0657 - val_accuracy: 0.5522\n",
            "Epoch 60/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0658 - accuracy: 0.5487 - val_loss: 0.0652 - val_accuracy: 0.5567\n",
            "Epoch 61/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0653 - accuracy: 0.5532 - val_loss: 0.0647 - val_accuracy: 0.5598\n",
            "Epoch 62/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0649 - accuracy: 0.5572 - val_loss: 0.0642 - val_accuracy: 0.5650\n",
            "Epoch 63/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0644 - accuracy: 0.5619 - val_loss: 0.0637 - val_accuracy: 0.5707\n",
            "Epoch 64/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0639 - accuracy: 0.5666 - val_loss: 0.0633 - val_accuracy: 0.5753\n",
            "Epoch 65/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0634 - accuracy: 0.5712 - val_loss: 0.0628 - val_accuracy: 0.5805\n",
            "Epoch 66/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0630 - accuracy: 0.5767 - val_loss: 0.0623 - val_accuracy: 0.5847\n",
            "Epoch 67/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0625 - accuracy: 0.5819 - val_loss: 0.0618 - val_accuracy: 0.5899\n",
            "Epoch 68/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0620 - accuracy: 0.5864 - val_loss: 0.0614 - val_accuracy: 0.5958\n",
            "Epoch 69/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0616 - accuracy: 0.5911 - val_loss: 0.0609 - val_accuracy: 0.6014\n",
            "Epoch 70/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0611 - accuracy: 0.5959 - val_loss: 0.0604 - val_accuracy: 0.6066\n",
            "Epoch 71/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0607 - accuracy: 0.6013 - val_loss: 0.0600 - val_accuracy: 0.6120\n",
            "Epoch 72/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0602 - accuracy: 0.6058 - val_loss: 0.0595 - val_accuracy: 0.6177\n",
            "Epoch 73/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0598 - accuracy: 0.6110 - val_loss: 0.0591 - val_accuracy: 0.6229\n",
            "Epoch 74/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0594 - accuracy: 0.6161 - val_loss: 0.0586 - val_accuracy: 0.6280\n",
            "Epoch 75/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0589 - accuracy: 0.6215 - val_loss: 0.0582 - val_accuracy: 0.6331\n",
            "Epoch 76/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0585 - accuracy: 0.6265 - val_loss: 0.0578 - val_accuracy: 0.6384\n",
            "Epoch 77/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0581 - accuracy: 0.6314 - val_loss: 0.0573 - val_accuracy: 0.6441\n",
            "Epoch 78/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0577 - accuracy: 0.6358 - val_loss: 0.0569 - val_accuracy: 0.6495\n",
            "Epoch 79/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0572 - accuracy: 0.6407 - val_loss: 0.0565 - val_accuracy: 0.6542\n",
            "Epoch 80/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0568 - accuracy: 0.6458 - val_loss: 0.0561 - val_accuracy: 0.6597\n",
            "Epoch 81/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0564 - accuracy: 0.6500 - val_loss: 0.0557 - val_accuracy: 0.6655\n",
            "Epoch 82/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0560 - accuracy: 0.6549 - val_loss: 0.0553 - val_accuracy: 0.6700\n",
            "Epoch 83/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0556 - accuracy: 0.6595 - val_loss: 0.0549 - val_accuracy: 0.6749\n",
            "Epoch 84/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0552 - accuracy: 0.6641 - val_loss: 0.0545 - val_accuracy: 0.6796\n",
            "Epoch 85/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0548 - accuracy: 0.6690 - val_loss: 0.0541 - val_accuracy: 0.6838\n",
            "Epoch 86/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0544 - accuracy: 0.6738 - val_loss: 0.0537 - val_accuracy: 0.6872\n",
            "Epoch 87/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0541 - accuracy: 0.6788 - val_loss: 0.0533 - val_accuracy: 0.6910\n",
            "Epoch 88/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0537 - accuracy: 0.6824 - val_loss: 0.0529 - val_accuracy: 0.6966\n",
            "Epoch 89/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0533 - accuracy: 0.6876 - val_loss: 0.0525 - val_accuracy: 0.7000\n",
            "Epoch 90/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0529 - accuracy: 0.6914 - val_loss: 0.0521 - val_accuracy: 0.7047\n",
            "Epoch 91/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0526 - accuracy: 0.6951 - val_loss: 0.0518 - val_accuracy: 0.7095\n",
            "Epoch 92/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0522 - accuracy: 0.6992 - val_loss: 0.0514 - val_accuracy: 0.7132\n",
            "Epoch 93/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0518 - accuracy: 0.7021 - val_loss: 0.0510 - val_accuracy: 0.7169\n",
            "Epoch 94/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0515 - accuracy: 0.7062 - val_loss: 0.0507 - val_accuracy: 0.7200\n",
            "Epoch 95/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0511 - accuracy: 0.7097 - val_loss: 0.0503 - val_accuracy: 0.7223\n",
            "Epoch 96/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0508 - accuracy: 0.7133 - val_loss: 0.0500 - val_accuracy: 0.7256\n",
            "Epoch 97/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0504 - accuracy: 0.7162 - val_loss: 0.0496 - val_accuracy: 0.7288\n",
            "Epoch 98/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0501 - accuracy: 0.7193 - val_loss: 0.0493 - val_accuracy: 0.7315\n",
            "Epoch 99/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0498 - accuracy: 0.7228 - val_loss: 0.0489 - val_accuracy: 0.7341\n",
            "Epoch 100/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0494 - accuracy: 0.7258 - val_loss: 0.0486 - val_accuracy: 0.7370\n",
            "Epoch 101/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0491 - accuracy: 0.7286 - val_loss: 0.0483 - val_accuracy: 0.7410\n",
            "Epoch 102/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0488 - accuracy: 0.7313 - val_loss: 0.0479 - val_accuracy: 0.7435\n",
            "Epoch 103/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0484 - accuracy: 0.7332 - val_loss: 0.0476 - val_accuracy: 0.7460\n",
            "Epoch 104/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0481 - accuracy: 0.7355 - val_loss: 0.0473 - val_accuracy: 0.7492\n",
            "Epoch 105/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0478 - accuracy: 0.7370 - val_loss: 0.0470 - val_accuracy: 0.7516\n",
            "Epoch 106/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0475 - accuracy: 0.7394 - val_loss: 0.0466 - val_accuracy: 0.7537\n",
            "Epoch 107/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0472 - accuracy: 0.7415 - val_loss: 0.0463 - val_accuracy: 0.7555\n",
            "Epoch 108/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0469 - accuracy: 0.7434 - val_loss: 0.0460 - val_accuracy: 0.7581\n",
            "Epoch 109/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0466 - accuracy: 0.7451 - val_loss: 0.0457 - val_accuracy: 0.7599\n",
            "Epoch 110/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0463 - accuracy: 0.7469 - val_loss: 0.0454 - val_accuracy: 0.7627\n",
            "Epoch 111/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0460 - accuracy: 0.7487 - val_loss: 0.0451 - val_accuracy: 0.7642\n",
            "Epoch 112/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0457 - accuracy: 0.7503 - val_loss: 0.0448 - val_accuracy: 0.7660\n",
            "Epoch 113/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0454 - accuracy: 0.7519 - val_loss: 0.0445 - val_accuracy: 0.7674\n",
            "Epoch 114/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0451 - accuracy: 0.7535 - val_loss: 0.0442 - val_accuracy: 0.7689\n",
            "Epoch 115/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0448 - accuracy: 0.7551 - val_loss: 0.0439 - val_accuracy: 0.7700\n",
            "Epoch 116/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0445 - accuracy: 0.7565 - val_loss: 0.0436 - val_accuracy: 0.7715\n",
            "Epoch 117/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0443 - accuracy: 0.7577 - val_loss: 0.0434 - val_accuracy: 0.7724\n",
            "Epoch 118/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0440 - accuracy: 0.7592 - val_loss: 0.0431 - val_accuracy: 0.7732\n",
            "Epoch 119/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0437 - accuracy: 0.7604 - val_loss: 0.0428 - val_accuracy: 0.7745\n",
            "Epoch 120/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0434 - accuracy: 0.7618 - val_loss: 0.0425 - val_accuracy: 0.7758\n",
            "Epoch 121/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0432 - accuracy: 0.7632 - val_loss: 0.0423 - val_accuracy: 0.7770\n",
            "Epoch 122/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0429 - accuracy: 0.7652 - val_loss: 0.0420 - val_accuracy: 0.7786\n",
            "Epoch 123/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0426 - accuracy: 0.7666 - val_loss: 0.0417 - val_accuracy: 0.7802\n",
            "Epoch 124/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0424 - accuracy: 0.7683 - val_loss: 0.0415 - val_accuracy: 0.7815\n",
            "Epoch 125/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0421 - accuracy: 0.7702 - val_loss: 0.0412 - val_accuracy: 0.7836\n",
            "Epoch 126/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0419 - accuracy: 0.7723 - val_loss: 0.0409 - val_accuracy: 0.7865\n",
            "Epoch 127/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0416 - accuracy: 0.7739 - val_loss: 0.0407 - val_accuracy: 0.7881\n",
            "Epoch 128/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0413 - accuracy: 0.7756 - val_loss: 0.0404 - val_accuracy: 0.7892\n",
            "Epoch 129/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0411 - accuracy: 0.7777 - val_loss: 0.0402 - val_accuracy: 0.7911\n",
            "Epoch 130/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0409 - accuracy: 0.7794 - val_loss: 0.0399 - val_accuracy: 0.7933\n",
            "Epoch 131/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0406 - accuracy: 0.7815 - val_loss: 0.0397 - val_accuracy: 0.7965\n",
            "Epoch 132/200\n",
            "60000/60000 [==============================] - 1s 24us/sample - loss: 0.0404 - accuracy: 0.7836 - val_loss: 0.0394 - val_accuracy: 0.7978\n",
            "Epoch 133/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0401 - accuracy: 0.7855 - val_loss: 0.0392 - val_accuracy: 0.8009\n",
            "Epoch 134/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0399 - accuracy: 0.7873 - val_loss: 0.0390 - val_accuracy: 0.8034\n",
            "Epoch 135/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0397 - accuracy: 0.7888 - val_loss: 0.0387 - val_accuracy: 0.8049\n",
            "Epoch 136/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0394 - accuracy: 0.7906 - val_loss: 0.0385 - val_accuracy: 0.8060\n",
            "Epoch 137/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0392 - accuracy: 0.7926 - val_loss: 0.0383 - val_accuracy: 0.8078\n",
            "Epoch 138/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0390 - accuracy: 0.7944 - val_loss: 0.0380 - val_accuracy: 0.8104\n",
            "Epoch 139/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0387 - accuracy: 0.7961 - val_loss: 0.0378 - val_accuracy: 0.8121\n",
            "Epoch 140/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0385 - accuracy: 0.7979 - val_loss: 0.0376 - val_accuracy: 0.8131\n",
            "Epoch 141/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0383 - accuracy: 0.7997 - val_loss: 0.0373 - val_accuracy: 0.8145\n",
            "Epoch 142/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0381 - accuracy: 0.8014 - val_loss: 0.0371 - val_accuracy: 0.8167\n",
            "Epoch 143/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0379 - accuracy: 0.8034 - val_loss: 0.0369 - val_accuracy: 0.8182\n",
            "Epoch 144/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0376 - accuracy: 0.8054 - val_loss: 0.0367 - val_accuracy: 0.8193\n",
            "Epoch 145/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0374 - accuracy: 0.8069 - val_loss: 0.0365 - val_accuracy: 0.8209\n",
            "Epoch 146/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0372 - accuracy: 0.8087 - val_loss: 0.0363 - val_accuracy: 0.8226\n",
            "Epoch 147/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0370 - accuracy: 0.8103 - val_loss: 0.0361 - val_accuracy: 0.8237\n",
            "Epoch 148/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0368 - accuracy: 0.8120 - val_loss: 0.0358 - val_accuracy: 0.8247\n",
            "Epoch 149/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0366 - accuracy: 0.8133 - val_loss: 0.0356 - val_accuracy: 0.8259\n",
            "Epoch 150/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0364 - accuracy: 0.8149 - val_loss: 0.0354 - val_accuracy: 0.8275\n",
            "Epoch 151/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0362 - accuracy: 0.8165 - val_loss: 0.0352 - val_accuracy: 0.8290\n",
            "Epoch 152/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0360 - accuracy: 0.8180 - val_loss: 0.0350 - val_accuracy: 0.8294\n",
            "Epoch 153/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0358 - accuracy: 0.8195 - val_loss: 0.0348 - val_accuracy: 0.8306\n",
            "Epoch 154/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0356 - accuracy: 0.8208 - val_loss: 0.0346 - val_accuracy: 0.8317\n",
            "Epoch 155/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0354 - accuracy: 0.8224 - val_loss: 0.0344 - val_accuracy: 0.8333\n",
            "Epoch 156/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0352 - accuracy: 0.8237 - val_loss: 0.0343 - val_accuracy: 0.8350\n",
            "Epoch 157/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0350 - accuracy: 0.8249 - val_loss: 0.0341 - val_accuracy: 0.8364\n",
            "Epoch 158/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0349 - accuracy: 0.8260 - val_loss: 0.0339 - val_accuracy: 0.8378\n",
            "Epoch 159/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0347 - accuracy: 0.8271 - val_loss: 0.0337 - val_accuracy: 0.8389\n",
            "Epoch 160/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0345 - accuracy: 0.8283 - val_loss: 0.0335 - val_accuracy: 0.8401\n",
            "Epoch 161/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0343 - accuracy: 0.8292 - val_loss: 0.0333 - val_accuracy: 0.8412\n",
            "Epoch 162/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0341 - accuracy: 0.8305 - val_loss: 0.0331 - val_accuracy: 0.8421\n",
            "Epoch 163/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0340 - accuracy: 0.8315 - val_loss: 0.0330 - val_accuracy: 0.8430\n",
            "Epoch 164/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0338 - accuracy: 0.8324 - val_loss: 0.0328 - val_accuracy: 0.8438\n",
            "Epoch 165/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0336 - accuracy: 0.8331 - val_loss: 0.0326 - val_accuracy: 0.8444\n",
            "Epoch 166/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0334 - accuracy: 0.8338 - val_loss: 0.0324 - val_accuracy: 0.8450\n",
            "Epoch 167/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0333 - accuracy: 0.8349 - val_loss: 0.0323 - val_accuracy: 0.8450\n",
            "Epoch 168/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0331 - accuracy: 0.8359 - val_loss: 0.0321 - val_accuracy: 0.8460\n",
            "Epoch 169/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0329 - accuracy: 0.8368 - val_loss: 0.0319 - val_accuracy: 0.8471\n",
            "Epoch 170/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0328 - accuracy: 0.8377 - val_loss: 0.0318 - val_accuracy: 0.8475\n",
            "Epoch 171/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0326 - accuracy: 0.8388 - val_loss: 0.0316 - val_accuracy: 0.8482\n",
            "Epoch 172/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0324 - accuracy: 0.8397 - val_loss: 0.0314 - val_accuracy: 0.8492\n",
            "Epoch 173/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0323 - accuracy: 0.8404 - val_loss: 0.0313 - val_accuracy: 0.8497\n",
            "Epoch 174/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0321 - accuracy: 0.8411 - val_loss: 0.0311 - val_accuracy: 0.8506\n",
            "Epoch 175/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0320 - accuracy: 0.8418 - val_loss: 0.0310 - val_accuracy: 0.8516\n",
            "Epoch 176/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0318 - accuracy: 0.8429 - val_loss: 0.0308 - val_accuracy: 0.8525\n",
            "Epoch 177/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0317 - accuracy: 0.8434 - val_loss: 0.0307 - val_accuracy: 0.8529\n",
            "Epoch 178/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0315 - accuracy: 0.8441 - val_loss: 0.0305 - val_accuracy: 0.8538\n",
            "Epoch 179/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0314 - accuracy: 0.8448 - val_loss: 0.0304 - val_accuracy: 0.8547\n",
            "Epoch 180/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0312 - accuracy: 0.8454 - val_loss: 0.0302 - val_accuracy: 0.8557\n",
            "Epoch 181/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0311 - accuracy: 0.8461 - val_loss: 0.0301 - val_accuracy: 0.8566\n",
            "Epoch 182/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0309 - accuracy: 0.8466 - val_loss: 0.0299 - val_accuracy: 0.8571\n",
            "Epoch 183/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0308 - accuracy: 0.8472 - val_loss: 0.0298 - val_accuracy: 0.8575\n",
            "Epoch 184/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0307 - accuracy: 0.8477 - val_loss: 0.0297 - val_accuracy: 0.8585\n",
            "Epoch 185/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0305 - accuracy: 0.8482 - val_loss: 0.0295 - val_accuracy: 0.8586\n",
            "Epoch 186/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0304 - accuracy: 0.8491 - val_loss: 0.0294 - val_accuracy: 0.8595\n",
            "Epoch 187/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0303 - accuracy: 0.8496 - val_loss: 0.0292 - val_accuracy: 0.8601\n",
            "Epoch 188/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0301 - accuracy: 0.8503 - val_loss: 0.0291 - val_accuracy: 0.8609\n",
            "Epoch 189/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0300 - accuracy: 0.8508 - val_loss: 0.0290 - val_accuracy: 0.8610\n",
            "Epoch 190/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0299 - accuracy: 0.8512 - val_loss: 0.0288 - val_accuracy: 0.8616\n",
            "Epoch 191/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0297 - accuracy: 0.8517 - val_loss: 0.0287 - val_accuracy: 0.8617\n",
            "Epoch 192/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0296 - accuracy: 0.8522 - val_loss: 0.0286 - val_accuracy: 0.8625\n",
            "Epoch 193/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0295 - accuracy: 0.8528 - val_loss: 0.0285 - val_accuracy: 0.8630\n",
            "Epoch 194/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0294 - accuracy: 0.8531 - val_loss: 0.0283 - val_accuracy: 0.8633\n",
            "Epoch 195/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0292 - accuracy: 0.8535 - val_loss: 0.0282 - val_accuracy: 0.8636\n",
            "Epoch 196/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0291 - accuracy: 0.8541 - val_loss: 0.0281 - val_accuracy: 0.8637\n",
            "Epoch 197/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0290 - accuracy: 0.8546 - val_loss: 0.0280 - val_accuracy: 0.8644\n",
            "Epoch 198/200\n",
            "60000/60000 [==============================] - 1s 22us/sample - loss: 0.0289 - accuracy: 0.8550 - val_loss: 0.0278 - val_accuracy: 0.8646\n",
            "Epoch 199/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0288 - accuracy: 0.8554 - val_loss: 0.0277 - val_accuracy: 0.8648\n",
            "Epoch 200/200\n",
            "60000/60000 [==============================] - 1s 23us/sample - loss: 0.0286 - accuracy: 0.8558 - val_loss: 0.0276 - val_accuracy: 0.8652\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f33765feba8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSAZqGuuZp2r",
        "colab_type": "text"
      },
      "source": [
        "#### Performing inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yyad-fM0Zu2e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_0 = X_valid[0].reshape(1, 784)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKj2dXZ_aAkb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inference = model.predict(valid_0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gecUhCPtagJt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "522d5f20-bb1d-4e84-9c6d-f994f8c28512"
      },
      "source": [
        "type(inference)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "numpy.ndarray"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGa48UQSatKe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "77503ce9-d36e-423c-b073-312de797f021"
      },
      "source": [
        "np.argmax(inference)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    }
  ]
}